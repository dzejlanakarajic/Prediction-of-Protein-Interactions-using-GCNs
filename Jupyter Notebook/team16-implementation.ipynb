{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "for-testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFt2av7bAorx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5fe3b8d2-0d0d-4b52-d37f-4a974a4a9bbe"
      },
      "source": [
        "!wget 'http://snap.stanford.edu/deepnetbio-ismb/ipynb/yeast.edgelist'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-19 13:25:36--  http://snap.stanford.edu/deepnetbio-ismb/ipynb/yeast.edgelist\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11758544 (11M) [text/plain]\n",
            "Saving to: ‘yeast.edgelist’\n",
            "\n",
            "yeast.edgelist      100%[===================>]  11.21M  3.24MB/s    in 4.0s    \n",
            "\n",
            "2020-07-19 13:25:41 (2.84 MB/s) - ‘yeast.edgelist’ saved [11758544/11758544]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1KDsY8v0z1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import torch\n",
        "import torch.nn.modules.loss\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import torch\n",
        "import torch.nn.modules.loss\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from torch import optim\n",
        "from torch.nn.modules.module import Module\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-BogZykg62z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7c00792a-718a-40ae-a959-e10eb697925a"
      },
      "source": [
        "!pip show torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: torch\n",
            "Version: 1.5.1+cu101\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: numpy, future\n",
            "Required-by: torchvision, torchtext, fastai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mirFVQuQvN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  adj = nx.adjacency_matrix(nx.read_edgelist(\"yeast.edgelist\",\n",
        "                                                   delimiter='\\t',\n",
        "                                                   create_using=nx.Graph()))\n",
        "  features = sp.identity(adj.shape[0])\n",
        "  features = torch.FloatTensor(np.array(features.todense()))\n",
        "\n",
        "  return adj, features\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "\n",
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 2% positive links\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 50.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 50.))\n",
        "\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b):\n",
        "        rows_close = np.all((a - b[:, None]) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        n_rnd = len(test_edges) - len(test_edges_false)\n",
        "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
        "        idxs_i = rnd[:n_rnd]                                        \n",
        "        idxs_j = rnd[n_rnd:]\n",
        "        for i in range(n_rnd):\n",
        "            idx_i = idxs_i[i]\n",
        "            idx_j = idxs_j[i]\n",
        "            if idx_i == idx_j:\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], edges_all):\n",
        "                continue\n",
        "            if test_edges_false:\n",
        "                if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                    continue\n",
        "                if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                    continue\n",
        "            test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        n_rnd = len(val_edges) - len(val_edges_false)\n",
        "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
        "        idxs_i = rnd[:n_rnd]                                        \n",
        "        idxs_j = rnd[n_rnd:]\n",
        "        for i in range(n_rnd):\n",
        "            idx_i = idxs_i[i]\n",
        "            idx_j = idxs_j[i]\n",
        "            if idx_i == idx_j:\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], train_edges):\n",
        "                continue\n",
        "            if ismember([idx_j, idx_i], train_edges):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], val_edges):\n",
        "                continue\n",
        "            if ismember([idx_j, idx_i], val_edges):\n",
        "                continue\n",
        "            if val_edges_false:\n",
        "                if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                    continue\n",
        "                if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                    continue\n",
        "            val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false\n",
        "\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    # return sparse_to_tuple(adj_normalized)\n",
        "    return sparse_mx_to_torch_sparse_tensor(adj_normalized)\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "\n",
        "def get_roc_score(emb, adj_orig, edges_pos, edges_neg):\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJmTFsDyRSA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, dropout=0., act=F.relu):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        input = F.dropout(input, self.dropout, self.training)\n",
        "        support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        output = self.act(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSYEX1YTTzwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCNModelVAE(nn.Module):\n",
        "    def __init__(self, input_feat_dim, hidden_dim1, hidden_dim2, dropout):\n",
        "        super(GCNModelVAE, self).__init__()\n",
        "        self.gc1 = GraphConvolution(input_feat_dim, hidden_dim1, dropout, act=F.relu)\n",
        "        self.gc2 = GraphConvolution(hidden_dim1, hidden_dim2, dropout, act=lambda x: x)\n",
        "        self.gc3 = GraphConvolution(hidden_dim1, hidden_dim2, dropout, act=lambda x: x)\n",
        "        self.dc = InnerProductDecoder(dropout, act=lambda x: x)\n",
        "\n",
        "    def encode(self, x, adj):\n",
        "        hidden1 = self.gc1(x, adj)\n",
        "        return self.gc2(hidden1, adj), self.gc3(hidden1, adj)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        mu, logvar = self.encode(x, adj)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.dc(z), mu, logvar\n",
        "\n",
        "\n",
        "class InnerProductDecoder(nn.Module):\n",
        "    \"\"\"Decoder for using inner product for prediction.\"\"\"\n",
        "\n",
        "    def __init__(self, dropout, act=torch.sigmoid):\n",
        "        super(InnerProductDecoder, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.dropout(z, self.dropout, training=self.training)\n",
        "        adj = self.act(torch.mm(z, z.t()))\n",
        "        return adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaaDqNgwT0ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(preds, labels, mu, logvar, n_nodes, norm, pos_weight):\n",
        "    cost = norm * F.binary_cross_entropy_with_logits(preds, labels, pos_weight=pos_weight)\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 / n_nodes * torch.mean(torch.sum(\n",
        "        1 + 2 * logvar - mu.pow(2) - logvar.exp().pow(2), 1))\n",
        "    return cost + KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyvb1PFAUzbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A91pbf8dUERX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', type=str, default='gcn_vae', help=\"models used\")\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=20, help='Number of epochs to train.')\n",
        "parser.add_argument('--hidden1', type=int, default=32, help='Number of units in hidden layer 1.')\n",
        "parser.add_argument('--hidden2', type=int, default=16, help='Number of units in hidden layer 2.')\n",
        "parser.add_argument('--lr', type=float, default=0.01, help='Initial learning rate.')\n",
        "parser.add_argument('--dropout', type=float, default=0., help='Dropout rate (1 - keep probability).')\n",
        "\n",
        "args = parser.parse_args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LIuV8z6VhnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj, features = load_data()\n",
        "n_nodes, feat_dim = features.shape\n",
        "\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y32YLgSpVmR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvdz3uWEVrkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "# adj_label = sparse_to_tuple(adj_label)\n",
        "adj_label = torch.FloatTensor(adj_label.toarray())\n",
        "\n",
        "pos_weight = torch.Tensor([float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()])\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3YCXflVVybx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GCNModelVAE(feat_dim, args.hidden1, args.hidden2, args.dropout)\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGQ-H-65XYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_emb = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0JIXhOB9c0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "72421eeb-0a04-4cc7-cd1f-7b6eca874a73"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "for epoch in range(args.epochs):\n",
        "        model = GCNModelVAE(feat_dim, args.hidden1, args.hidden2, args.dropout)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "        hidden_emb = None\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        recovered, mu, logvar = model(features, adj_norm)\n",
        "        loss = loss_function(preds=recovered, labels=adj_label,\n",
        "                             mu=mu, logvar=logvar, n_nodes=n_nodes,\n",
        "                             norm=norm, pos_weight=pos_weight)\n",
        "        loss.backward()\n",
        "        cur_loss = loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        hidden_emb = mu.data.numpy()\n",
        "        roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
        "\n",
        "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
        "              \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "              \"time=\", \"{:.5f}\".format(time.time() - t)\n",
        "              )\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
        "print('Test ROC score: ' + str(roc_score))\n",
        "print('Test AP score: ' + str(ap_score))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 train_loss= 1.72352 val_ap= 0.63463 time= 1.79950\n",
            "Epoch: 0002 train_loss= 1.73330 val_ap= 0.63891 time= 1.80722\n",
            "Epoch: 0003 train_loss= 1.73539 val_ap= 0.66264 time= 1.79907\n",
            "Epoch: 0004 train_loss= 1.71998 val_ap= 0.65141 time= 1.79061\n",
            "Epoch: 0005 train_loss= 1.72761 val_ap= 0.67867 time= 1.80107\n",
            "Epoch: 0006 train_loss= 1.72623 val_ap= 0.65130 time= 1.78900\n",
            "Epoch: 0007 train_loss= 1.73250 val_ap= 0.65514 time= 1.79177\n",
            "Epoch: 0008 train_loss= 1.73799 val_ap= 0.64825 time= 1.78052\n",
            "Epoch: 0009 train_loss= 1.72583 val_ap= 0.65094 time= 1.81512\n",
            "Epoch: 0010 train_loss= 1.72268 val_ap= 0.67309 time= 1.78764\n",
            "Epoch: 0011 train_loss= 1.73906 val_ap= 0.64871 time= 1.78613\n",
            "Epoch: 0012 train_loss= 1.72031 val_ap= 0.63863 time= 1.78544\n",
            "Epoch: 0013 train_loss= 1.72186 val_ap= 0.65757 time= 1.80489\n",
            "Epoch: 0014 train_loss= 1.71460 val_ap= 0.63926 time= 1.80908\n",
            "Epoch: 0015 train_loss= 1.72983 val_ap= 0.66232 time= 1.81706\n",
            "Epoch: 0016 train_loss= 1.74132 val_ap= 0.64449 time= 1.82356\n",
            "Epoch: 0017 train_loss= 1.73268 val_ap= 0.65626 time= 1.82128\n",
            "Epoch: 0018 train_loss= 1.73154 val_ap= 0.67073 time= 1.80928\n",
            "Epoch: 0019 train_loss= 1.72295 val_ap= 0.66403 time= 1.80664\n",
            "Epoch: 0020 train_loss= 1.72374 val_ap= 0.65169 time= 1.78638\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7427943855899272\n",
            "Test AP score: 0.6579602799424729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRdm7Q69d0Tz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "58290b35-2074-4f91-f2b6-1998810ccb73"
      },
      "source": [
        "print(\"Loaded\",adj.shape[0],\"nodes\")\n",
        "print(\"Loaded\",adj.sum(),\"edges\")\n",
        "print()\n",
        "print(\"-- Data format --\")\n",
        "print(\"Full graph adjacency shape:    \", adj.shape, \"\\t\",             type(adj), \"number of indices\", len(adj.indices))\n",
        "print(\"Training graph adjacency shape:\", adj_train.shape, \"\\t\",       type(adj_train), \"number of indices\", len(adj_train.indices))\n",
        "print(\"val_edges:                     \", val_edges.shape, \"\\t\",       type(val_edges))\n",
        "print(\"val_edges_false:               \", len(val_edges_false), \"\\t\\t\",type(val_edges_false))\n",
        "print(\"test_edges:                    \", test_edges.shape,\"\\t\",       type(test_edges))\n",
        "print(\"test_edges_false:              \", len(test_edges_false),\"\\t\\t\",type(test_edges_false))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 6526 nodes\n",
            "Loaded 1062675 edges\n",
            "\n",
            "-- Data format --\n",
            "Full graph adjacency shape:     (6526, 6526) \t <class 'scipy.sparse.csr.csr_matrix'> number of indices 1062675\n",
            "Training graph adjacency shape: (6526, 6526) \t <class 'scipy.sparse.csr.csr_matrix'> number of indices 1018554\n",
            "val_edges:                      (10609, 2) \t <class 'numpy.ndarray'>\n",
            "val_edges_false:                10609 \t\t <class 'list'>\n",
            "test_edges:                     (10609, 2) \t <class 'numpy.ndarray'>\n",
            "test_edges_false:               10609 \t\t <class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCl2OGtobtDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fdabf76-e341-42c5-d1f6-5f91a7e81df8"
      },
      "source": [
        "import itertools\n",
        "\n",
        "hyperparams = {\n",
        "    \"hidden1\": [256, 128, 64, 32],\n",
        "    \"hidden2\": [64, 32, 16, 8],\n",
        "    \"lr\": [0.001, 0.01, 0.1]}\n",
        "\n",
        "keys = hyperparams.keys()\n",
        "values = (hyperparams[key] for key in keys)\n",
        "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
        "print(\"Total combinations:\" ,len(combinations), \".\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total combinations: 48 .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxuYrR3ofGiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7247b3d5-4fe1-4c70-c90d-746a25193654"
      },
      "source": [
        "combinations[0]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hidden1': 256, 'hidden2': 64, 'lr': 0.001}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD5r7Gy6gp1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f6e0692e-3a75-44b6-c6ba-eebfedc525d3"
      },
      "source": [
        "for key in hyperparams.keys():\n",
        "  print(key)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden1\n",
            "hidden2\n",
            "lr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSj3jcnIlmUu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2661483a-ae21-44d6-9f0e-0148a62c3a45"
      },
      "source": [
        "combinations[1]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hidden1': 256, 'hidden2': 64, 'lr': 0.01}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnwSE9Iul6ur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "791f8904-1da4-460d-aa10-95e281943225"
      },
      "source": [
        "for d in combinations:\n",
        "    print(d['hidden1'], d['hidden2'], d['lr'])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "256 64 0.001\n",
            "256 64 0.01\n",
            "256 64 0.1\n",
            "256 32 0.001\n",
            "256 32 0.01\n",
            "256 32 0.1\n",
            "256 16 0.001\n",
            "256 16 0.01\n",
            "256 16 0.1\n",
            "256 8 0.001\n",
            "256 8 0.01\n",
            "256 8 0.1\n",
            "128 64 0.001\n",
            "128 64 0.01\n",
            "128 64 0.1\n",
            "128 32 0.001\n",
            "128 32 0.01\n",
            "128 32 0.1\n",
            "128 16 0.001\n",
            "128 16 0.01\n",
            "128 16 0.1\n",
            "128 8 0.001\n",
            "128 8 0.01\n",
            "128 8 0.1\n",
            "64 64 0.001\n",
            "64 64 0.01\n",
            "64 64 0.1\n",
            "64 32 0.001\n",
            "64 32 0.01\n",
            "64 32 0.1\n",
            "64 16 0.001\n",
            "64 16 0.01\n",
            "64 16 0.1\n",
            "64 8 0.001\n",
            "64 8 0.01\n",
            "64 8 0.1\n",
            "32 64 0.001\n",
            "32 64 0.01\n",
            "32 64 0.1\n",
            "32 32 0.001\n",
            "32 32 0.01\n",
            "32 32 0.1\n",
            "32 16 0.001\n",
            "32 16 0.01\n",
            "32 16 0.1\n",
            "32 8 0.001\n",
            "32 8 0.01\n",
            "32 8 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyhnQGEJ9N1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file1 = open(\"all_hyperparam_combinations.txt\",\"w\") \n",
        "for d in combinations:\n",
        "  file1.write(\"hidenn1:{}, hidden2:{}, lr:{}\\n\".format(d['hidden1'], d['hidden2'], d['lr']))\n",
        "file1.close()"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckyXRZ9Ymyoi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88d56c4a-0843-418b-a6a2-81c7828a7b2e"
      },
      "source": [
        "file2 = open(\"20-epochs.txt\",\"w\") \n",
        "\n",
        "for d in combinations:\n",
        "  file2.write(\"Settings: hidden1{}, hidden2{}, lr:{}\\n\".format(d['hidden1'], d['hidden2'], d['lr']))\n",
        "  print(\"Settings:\", d['hidden1'], d['hidden2'], d['lr'])\n",
        "  for epoch in range(20): #5,10,15,20\n",
        "    #print(\"Settings:\", d['hidden1'], d['hidden2'], d['lr'])\n",
        "    model = GCNModelVAE(feat_dim, d['hidden1'], d['hidden2'], args.dropout)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=d['lr'])\n",
        "    hidden_emb = None\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    recovered, mu, logvar = model(features, adj_norm)\n",
        "    loss = loss_function(preds=recovered, labels=adj_label, mu=mu, logvar=logvar, n_nodes=n_nodes, norm=norm, pos_weight=pos_weight)\n",
        "    loss.backward()\n",
        "    cur_loss = loss.item()\n",
        "    optimizer.step()\n",
        "\n",
        "    hidden_emb = mu.data.numpy()\n",
        "    roc_curr, ap_curr = get_roc_score(hidden_emb, adj_orig, val_edges, val_edges_false)\n",
        "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss), \"val_ap=\", \"{:.5f}\".format(ap_curr), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "    file2.write(\"\\n\")\n",
        "    file2.write(\"Epoch %04d\" % (epoch + 1) )\n",
        "    file2.write(\" train loss= {:.5f}\".format(cur_loss))\n",
        "    file2.write(\" val_ap= {:.5f}\".format(ap_curr))\n",
        "    file2.write(\" time= {:.5f}\".format(time.time() - t ))\n",
        "    file2.write(\"\\n\")\n",
        "    \n",
        "  print(\"Optimization Finished!\")\n",
        "  file2.write(\"Optimization Finished! \\n\")\n",
        "  roc_score, ap_score = get_roc_score(hidden_emb, adj_orig, test_edges, test_edges_false)\n",
        "  print('Test ROC score: ' + str(roc_score))\n",
        "  print('Test AP score: ' + str(ap_score))\n",
        "  file2.write(\"Test ROC score: {}\\n\".format(str(roc_score)))\n",
        "  file2.write(\"Test AP score: {}\\n\".format(str(ap_score)))\n",
        "  file2.write(\"\\n\")\n",
        "\n",
        "file2.close()"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Settings: 256 64 0.001\n",
            "Epoch: 0001 train_loss= 3.27924 val_ap= 0.65972 time= 2.47072\n",
            "Epoch: 0002 train_loss= 3.25054 val_ap= 0.65873 time= 2.44192\n",
            "Epoch: 0003 train_loss= 3.24807 val_ap= 0.64849 time= 2.45296\n",
            "Epoch: 0004 train_loss= 3.25116 val_ap= 0.65905 time= 2.46442\n",
            "Epoch: 0005 train_loss= 3.25636 val_ap= 0.65407 time= 2.44182\n",
            "Epoch: 0006 train_loss= 3.26239 val_ap= 0.66069 time= 2.45104\n",
            "Epoch: 0007 train_loss= 3.24739 val_ap= 0.65514 time= 2.44635\n",
            "Epoch: 0008 train_loss= 3.25308 val_ap= 0.64955 time= 2.45240\n",
            "Epoch: 0009 train_loss= 3.25037 val_ap= 0.65717 time= 2.45109\n",
            "Epoch: 0010 train_loss= 3.24916 val_ap= 0.66028 time= 2.43430\n",
            "Epoch: 0011 train_loss= 3.25476 val_ap= 0.65467 time= 2.45500\n",
            "Epoch: 0012 train_loss= 3.26975 val_ap= 0.64997 time= 2.41686\n",
            "Epoch: 0013 train_loss= 3.26772 val_ap= 0.64576 time= 2.43490\n",
            "Epoch: 0014 train_loss= 3.26702 val_ap= 0.65169 time= 2.45300\n",
            "Epoch: 0015 train_loss= 3.24487 val_ap= 0.65052 time= 2.49831\n",
            "Epoch: 0016 train_loss= 3.26059 val_ap= 0.65142 time= 2.45536\n",
            "Epoch: 0017 train_loss= 3.24847 val_ap= 0.64631 time= 2.47044\n",
            "Epoch: 0018 train_loss= 3.25457 val_ap= 0.64894 time= 2.48447\n",
            "Epoch: 0019 train_loss= 3.26689 val_ap= 0.65881 time= 2.42516\n",
            "Epoch: 0020 train_loss= 3.25191 val_ap= 0.66079 time= 2.45855\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7504564713269549\n",
            "Test AP score: 0.6689479222757978\n",
            "Settings: 256 64 0.01\n",
            "Epoch: 0001 train_loss= 3.25485 val_ap= 0.65177 time= 2.46872\n",
            "Epoch: 0002 train_loss= 3.25671 val_ap= 0.65300 time= 2.43160\n",
            "Epoch: 0003 train_loss= 3.26965 val_ap= 0.65235 time= 2.48767\n",
            "Epoch: 0004 train_loss= 3.25130 val_ap= 0.64356 time= 2.46168\n",
            "Epoch: 0005 train_loss= 3.23738 val_ap= 0.64675 time= 2.48809\n",
            "Epoch: 0006 train_loss= 3.27232 val_ap= 0.64778 time= 2.45689\n",
            "Epoch: 0007 train_loss= 3.25177 val_ap= 0.66463 time= 2.45970\n",
            "Epoch: 0008 train_loss= 3.25246 val_ap= 0.64614 time= 2.43847\n",
            "Epoch: 0009 train_loss= 3.25458 val_ap= 0.65534 time= 2.45022\n",
            "Epoch: 0010 train_loss= 3.25140 val_ap= 0.65301 time= 2.43276\n",
            "Epoch: 0011 train_loss= 3.25927 val_ap= 0.64846 time= 2.46580\n",
            "Epoch: 0012 train_loss= 3.25256 val_ap= 0.65369 time= 2.45227\n",
            "Epoch: 0013 train_loss= 3.25786 val_ap= 0.65016 time= 2.46493\n",
            "Epoch: 0014 train_loss= 3.25722 val_ap= 0.63947 time= 2.44000\n",
            "Epoch: 0015 train_loss= 3.24140 val_ap= 0.65519 time= 2.46918\n",
            "Epoch: 0016 train_loss= 3.24364 val_ap= 0.65360 time= 2.42461\n",
            "Epoch: 0017 train_loss= 3.25772 val_ap= 0.65060 time= 2.44980\n",
            "Epoch: 0018 train_loss= 3.24977 val_ap= 0.65477 time= 2.46078\n",
            "Epoch: 0019 train_loss= 3.24095 val_ap= 0.65751 time= 2.45655\n",
            "Epoch: 0020 train_loss= 3.25131 val_ap= 0.65206 time= 2.44719\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7446606881735559\n",
            "Test AP score: 0.6604940222948746\n",
            "Settings: 256 64 0.1\n",
            "Epoch: 0001 train_loss= 3.25290 val_ap= 0.64829 time= 2.45641\n",
            "Epoch: 0002 train_loss= 3.23921 val_ap= 0.64756 time= 2.44437\n",
            "Epoch: 0003 train_loss= 3.26210 val_ap= 0.64971 time= 2.44128\n",
            "Epoch: 0004 train_loss= 3.24680 val_ap= 0.65469 time= 2.44789\n",
            "Epoch: 0005 train_loss= 3.26490 val_ap= 0.65229 time= 2.44268\n",
            "Epoch: 0006 train_loss= 3.23982 val_ap= 0.65455 time= 2.44665\n",
            "Epoch: 0007 train_loss= 3.25887 val_ap= 0.65421 time= 2.47470\n",
            "Epoch: 0008 train_loss= 3.27417 val_ap= 0.65822 time= 2.44301\n",
            "Epoch: 0009 train_loss= 3.28251 val_ap= 0.64534 time= 2.44955\n",
            "Epoch: 0010 train_loss= 3.26312 val_ap= 0.64976 time= 2.44852\n",
            "Epoch: 0011 train_loss= 3.26733 val_ap= 0.64774 time= 2.45104\n",
            "Epoch: 0012 train_loss= 3.26346 val_ap= 0.64513 time= 2.42677\n",
            "Epoch: 0013 train_loss= 3.25339 val_ap= 0.64800 time= 2.45350\n",
            "Epoch: 0014 train_loss= 3.24832 val_ap= 0.64151 time= 2.42271\n",
            "Epoch: 0015 train_loss= 3.24116 val_ap= 0.65289 time= 2.45091\n",
            "Epoch: 0016 train_loss= 3.25039 val_ap= 0.65150 time= 2.45750\n",
            "Epoch: 0017 train_loss= 3.23599 val_ap= 0.65405 time= 2.46072\n",
            "Epoch: 0018 train_loss= 3.25704 val_ap= 0.65250 time= 2.43430\n",
            "Epoch: 0019 train_loss= 3.25354 val_ap= 0.65327 time= 2.44043\n",
            "Epoch: 0020 train_loss= 3.25421 val_ap= 0.65940 time= 2.43176\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7498550588866558\n",
            "Test AP score: 0.6674480979413743\n",
            "Settings: 256 32 0.001\n",
            "Epoch: 0001 train_loss= 2.35538 val_ap= 0.64605 time= 2.28321\n",
            "Epoch: 0002 train_loss= 2.34664 val_ap= 0.65500 time= 2.25877\n",
            "Epoch: 0003 train_loss= 2.33398 val_ap= 0.66295 time= 2.27947\n",
            "Epoch: 0004 train_loss= 2.34726 val_ap= 0.64496 time= 2.28143\n",
            "Epoch: 0005 train_loss= 2.34696 val_ap= 0.65607 time= 2.28464\n",
            "Epoch: 0006 train_loss= 2.33814 val_ap= 0.65079 time= 2.27664\n",
            "Epoch: 0007 train_loss= 2.36100 val_ap= 0.65362 time= 2.28916\n",
            "Epoch: 0008 train_loss= 2.35385 val_ap= 0.65024 time= 2.27157\n",
            "Epoch: 0009 train_loss= 2.35316 val_ap= 0.64997 time= 2.29161\n",
            "Epoch: 0010 train_loss= 2.34424 val_ap= 0.65857 time= 2.26708\n",
            "Epoch: 0011 train_loss= 2.35002 val_ap= 0.65199 time= 2.28275\n",
            "Epoch: 0012 train_loss= 2.34859 val_ap= 0.64937 time= 2.30008\n",
            "Epoch: 0013 train_loss= 2.34967 val_ap= 0.66482 time= 2.28214\n",
            "Epoch: 0014 train_loss= 2.34724 val_ap= 0.64706 time= 2.27768\n",
            "Epoch: 0015 train_loss= 2.34877 val_ap= 0.65701 time= 2.27111\n",
            "Epoch: 0016 train_loss= 2.33558 val_ap= 0.64223 time= 2.27905\n",
            "Epoch: 0017 train_loss= 2.35985 val_ap= 0.65558 time= 2.30015\n",
            "Epoch: 0018 train_loss= 2.34283 val_ap= 0.65703 time= 2.27971\n",
            "Epoch: 0019 train_loss= 2.34598 val_ap= 0.66321 time= 2.28850\n",
            "Epoch: 0020 train_loss= 2.36302 val_ap= 0.65723 time= 2.28679\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7502754865152944\n",
            "Test AP score: 0.6650458598523815\n",
            "Settings: 256 32 0.01\n",
            "Epoch: 0001 train_loss= 2.35079 val_ap= 0.66343 time= 2.30229\n",
            "Epoch: 0002 train_loss= 2.35084 val_ap= 0.65720 time= 2.28916\n",
            "Epoch: 0003 train_loss= 2.36572 val_ap= 0.66513 time= 2.30760\n",
            "Epoch: 0004 train_loss= 2.35082 val_ap= 0.65774 time= 2.28686\n",
            "Epoch: 0005 train_loss= 2.33912 val_ap= 0.65688 time= 2.27729\n",
            "Epoch: 0006 train_loss= 2.34869 val_ap= 0.65495 time= 2.29319\n",
            "Epoch: 0007 train_loss= 2.36049 val_ap= 0.64489 time= 2.26902\n",
            "Epoch: 0008 train_loss= 2.33434 val_ap= 0.65259 time= 2.25689\n",
            "Epoch: 0009 train_loss= 2.35853 val_ap= 0.65079 time= 2.29811\n",
            "Epoch: 0010 train_loss= 2.35309 val_ap= 0.64936 time= 2.29382\n",
            "Epoch: 0011 train_loss= 2.35537 val_ap= 0.65386 time= 2.30701\n",
            "Epoch: 0012 train_loss= 2.36744 val_ap= 0.65000 time= 2.27858\n",
            "Epoch: 0013 train_loss= 2.35362 val_ap= 0.65192 time= 2.29506\n",
            "Epoch: 0014 train_loss= 2.34963 val_ap= 0.66009 time= 2.27998\n",
            "Epoch: 0015 train_loss= 2.35645 val_ap= 0.65209 time= 2.28947\n",
            "Epoch: 0016 train_loss= 2.35578 val_ap= 0.65816 time= 2.29287\n",
            "Epoch: 0017 train_loss= 2.34790 val_ap= 0.64996 time= 2.27835\n",
            "Epoch: 0018 train_loss= 2.35617 val_ap= 0.65336 time= 2.29198\n",
            "Epoch: 0019 train_loss= 2.34498 val_ap= 0.65271 time= 2.28801\n",
            "Epoch: 0020 train_loss= 2.33761 val_ap= 0.65477 time= 2.25841\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7451509908660777\n",
            "Test AP score: 0.660893229241035\n",
            "Settings: 256 32 0.1\n",
            "Epoch: 0001 train_loss= 2.36307 val_ap= 0.66268 time= 2.27870\n",
            "Epoch: 0002 train_loss= 2.35899 val_ap= 0.64724 time= 2.25324\n",
            "Epoch: 0003 train_loss= 2.34701 val_ap= 0.65177 time= 2.28031\n",
            "Epoch: 0004 train_loss= 2.36504 val_ap= 0.66051 time= 2.25763\n",
            "Epoch: 0005 train_loss= 2.35850 val_ap= 0.65230 time= 2.25974\n",
            "Epoch: 0006 train_loss= 2.35255 val_ap= 0.65078 time= 2.26185\n",
            "Epoch: 0007 train_loss= 2.34478 val_ap= 0.67084 time= 2.26429\n",
            "Epoch: 0008 train_loss= 2.35812 val_ap= 0.64429 time= 2.26640\n",
            "Epoch: 0009 train_loss= 2.34742 val_ap= 0.64947 time= 2.27382\n",
            "Epoch: 0010 train_loss= 2.35081 val_ap= 0.65622 time= 2.27060\n",
            "Epoch: 0011 train_loss= 2.34800 val_ap= 0.65057 time= 2.27316\n",
            "Epoch: 0012 train_loss= 2.33526 val_ap= 0.65758 time= 2.26666\n",
            "Epoch: 0013 train_loss= 2.34510 val_ap= 0.64743 time= 2.29362\n",
            "Epoch: 0014 train_loss= 2.35277 val_ap= 0.64894 time= 2.29704\n",
            "Epoch: 0015 train_loss= 2.35116 val_ap= 0.65390 time= 2.27992\n",
            "Epoch: 0016 train_loss= 2.35143 val_ap= 0.64666 time= 2.25604\n",
            "Epoch: 0017 train_loss= 2.35417 val_ap= 0.64820 time= 2.28039\n",
            "Epoch: 0018 train_loss= 2.34400 val_ap= 0.65329 time= 2.29557\n",
            "Epoch: 0019 train_loss= 2.34668 val_ap= 0.65051 time= 2.29407\n",
            "Epoch: 0020 train_loss= 2.33826 val_ap= 0.65081 time= 2.29549\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7430443836330345\n",
            "Test AP score: 0.6568853214634992\n",
            "Settings: 256 16 0.001\n",
            "Epoch: 0001 train_loss= 1.74125 val_ap= 0.65320 time= 2.25024\n",
            "Epoch: 0002 train_loss= 1.72350 val_ap= 0.64367 time= 2.24748\n",
            "Epoch: 0003 train_loss= 1.73577 val_ap= 0.65477 time= 2.25040\n",
            "Epoch: 0004 train_loss= 1.73803 val_ap= 0.65706 time= 2.26722\n",
            "Epoch: 0005 train_loss= 1.70824 val_ap= 0.64151 time= 2.25937\n",
            "Epoch: 0006 train_loss= 1.72500 val_ap= 0.64718 time= 2.24565\n",
            "Epoch: 0007 train_loss= 1.72900 val_ap= 0.64928 time= 2.26298\n",
            "Epoch: 0008 train_loss= 1.73406 val_ap= 0.66430 time= 2.25075\n",
            "Epoch: 0009 train_loss= 1.72520 val_ap= 0.64272 time= 2.25569\n",
            "Epoch: 0010 train_loss= 1.73519 val_ap= 0.66272 time= 2.22295\n",
            "Epoch: 0011 train_loss= 1.73262 val_ap= 0.65002 time= 2.23704\n",
            "Epoch: 0012 train_loss= 1.72029 val_ap= 0.64673 time= 2.24001\n",
            "Epoch: 0013 train_loss= 1.71379 val_ap= 0.66952 time= 2.25857\n",
            "Epoch: 0014 train_loss= 1.72582 val_ap= 0.65239 time= 2.23866\n",
            "Epoch: 0015 train_loss= 1.72234 val_ap= 0.65748 time= 2.24581\n",
            "Epoch: 0016 train_loss= 1.74534 val_ap= 0.66551 time= 2.21897\n",
            "Epoch: 0017 train_loss= 1.72723 val_ap= 0.67499 time= 2.24226\n",
            "Epoch: 0018 train_loss= 1.71736 val_ap= 0.66415 time= 2.21395\n",
            "Epoch: 0019 train_loss= 1.74324 val_ap= 0.65601 time= 2.29205\n",
            "Epoch: 0020 train_loss= 1.72359 val_ap= 0.65837 time= 2.23774\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.748325879386053\n",
            "Test AP score: 0.6641553096480322\n",
            "Settings: 256 16 0.01\n",
            "Epoch: 0001 train_loss= 1.73329 val_ap= 0.66772 time= 2.24526\n",
            "Epoch: 0002 train_loss= 1.73156 val_ap= 0.67081 time= 2.22375\n",
            "Epoch: 0003 train_loss= 1.72868 val_ap= 0.65042 time= 2.22445\n",
            "Epoch: 0004 train_loss= 1.72508 val_ap= 0.66187 time= 2.21961\n",
            "Epoch: 0005 train_loss= 1.72774 val_ap= 0.66411 time= 2.27276\n",
            "Epoch: 0006 train_loss= 1.73044 val_ap= 0.64946 time= 2.23823\n",
            "Epoch: 0007 train_loss= 1.73912 val_ap= 0.67104 time= 2.25246\n",
            "Epoch: 0008 train_loss= 1.72023 val_ap= 0.66709 time= 2.26213\n",
            "Epoch: 0009 train_loss= 1.73926 val_ap= 0.65699 time= 2.26733\n",
            "Epoch: 0010 train_loss= 1.73761 val_ap= 0.66651 time= 2.25015\n",
            "Epoch: 0011 train_loss= 1.73871 val_ap= 0.66985 time= 2.21859\n",
            "Epoch: 0012 train_loss= 1.72664 val_ap= 0.67625 time= 2.22572\n",
            "Epoch: 0013 train_loss= 1.73963 val_ap= 0.65944 time= 2.21157\n",
            "Epoch: 0014 train_loss= 1.73345 val_ap= 0.66022 time= 2.22143\n",
            "Epoch: 0015 train_loss= 1.72654 val_ap= 0.65364 time= 2.22547\n",
            "Epoch: 0016 train_loss= 1.73209 val_ap= 0.65606 time= 2.22629\n",
            "Epoch: 0017 train_loss= 1.73132 val_ap= 0.66506 time= 2.22664\n",
            "Epoch: 0018 train_loss= 1.71824 val_ap= 0.66230 time= 2.21400\n",
            "Epoch: 0019 train_loss= 1.72740 val_ap= 0.63768 time= 2.24874\n",
            "Epoch: 0020 train_loss= 1.72097 val_ap= 0.65569 time= 2.24913\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.746958706613767\n",
            "Test AP score: 0.6620771136939355\n",
            "Settings: 256 16 0.1\n",
            "Epoch: 0001 train_loss= 1.72160 val_ap= 0.67376 time= 2.27428\n",
            "Epoch: 0002 train_loss= 1.72775 val_ap= 0.65919 time= 2.26805\n",
            "Epoch: 0003 train_loss= 1.73875 val_ap= 0.64109 time= 2.24033\n",
            "Epoch: 0004 train_loss= 1.72911 val_ap= 0.67341 time= 2.22823\n",
            "Epoch: 0005 train_loss= 1.73535 val_ap= 0.64645 time= 2.24027\n",
            "Epoch: 0006 train_loss= 1.72664 val_ap= 0.65352 time= 2.21752\n",
            "Epoch: 0007 train_loss= 1.73266 val_ap= 0.66688 time= 2.24348\n",
            "Epoch: 0008 train_loss= 1.73341 val_ap= 0.65341 time= 2.25399\n",
            "Epoch: 0009 train_loss= 1.72988 val_ap= 0.65702 time= 2.23616\n",
            "Epoch: 0010 train_loss= 1.73794 val_ap= 0.67316 time= 2.22575\n",
            "Epoch: 0011 train_loss= 1.72333 val_ap= 0.65726 time= 2.26676\n",
            "Epoch: 0012 train_loss= 1.72553 val_ap= 0.68993 time= 2.28672\n",
            "Epoch: 0013 train_loss= 1.73194 val_ap= 0.65962 time= 2.25052\n",
            "Epoch: 0014 train_loss= 1.72875 val_ap= 0.64872 time= 2.26359\n",
            "Epoch: 0015 train_loss= 1.73893 val_ap= 0.64887 time= 2.24806\n",
            "Epoch: 0016 train_loss= 1.73218 val_ap= 0.65747 time= 2.24905\n",
            "Epoch: 0017 train_loss= 1.72698 val_ap= 0.63840 time= 2.23623\n",
            "Epoch: 0018 train_loss= 1.72610 val_ap= 0.65292 time= 2.21749\n",
            "Epoch: 0019 train_loss= 1.73284 val_ap= 0.65374 time= 2.22515\n",
            "Epoch: 0020 train_loss= 1.73835 val_ap= 0.64174 time= 2.20794\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7382456650872415\n",
            "Test AP score: 0.6479777030904518\n",
            "Settings: 256 8 0.001\n",
            "Epoch: 0001 train_loss= 1.31478 val_ap= 0.68226 time= 2.20497\n",
            "Epoch: 0002 train_loss= 1.29744 val_ap= 0.66674 time= 2.19101\n",
            "Epoch: 0003 train_loss= 1.31964 val_ap= 0.65359 time= 2.20844\n",
            "Epoch: 0004 train_loss= 1.32481 val_ap= 0.64477 time= 2.19651\n",
            "Epoch: 0005 train_loss= 1.32068 val_ap= 0.66240 time= 2.22388\n",
            "Epoch: 0006 train_loss= 1.29564 val_ap= 0.64683 time= 2.21329\n",
            "Epoch: 0007 train_loss= 1.32353 val_ap= 0.66563 time= 2.22944\n",
            "Epoch: 0008 train_loss= 1.30530 val_ap= 0.67187 time= 2.22997\n",
            "Epoch: 0009 train_loss= 1.31697 val_ap= 0.66166 time= 2.22432\n",
            "Epoch: 0010 train_loss= 1.31518 val_ap= 0.66840 time= 2.20650\n",
            "Epoch: 0011 train_loss= 1.30903 val_ap= 0.64093 time= 2.24357\n",
            "Epoch: 0012 train_loss= 1.30775 val_ap= 0.66829 time= 2.20605\n",
            "Epoch: 0013 train_loss= 1.30335 val_ap= 0.66478 time= 2.21397\n",
            "Epoch: 0014 train_loss= 1.30972 val_ap= 0.65620 time= 2.22824\n",
            "Epoch: 0015 train_loss= 1.31654 val_ap= 0.65609 time= 2.25252\n",
            "Epoch: 0016 train_loss= 1.31254 val_ap= 0.67365 time= 2.24450\n",
            "Epoch: 0017 train_loss= 1.31132 val_ap= 0.65223 time= 2.24058\n",
            "Epoch: 0018 train_loss= 1.31090 val_ap= 0.64994 time= 2.21913\n",
            "Epoch: 0019 train_loss= 1.30980 val_ap= 0.63916 time= 2.23054\n",
            "Epoch: 0020 train_loss= 1.30906 val_ap= 0.64007 time= 2.21074\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7374613531456942\n",
            "Test AP score: 0.6428705457577747\n",
            "Settings: 256 8 0.01\n",
            "Epoch: 0001 train_loss= 1.31899 val_ap= 0.64529 time= 2.21648\n",
            "Epoch: 0002 train_loss= 1.29742 val_ap= 0.66297 time= 2.24473\n",
            "Epoch: 0003 train_loss= 1.32011 val_ap= 0.64311 time= 2.24299\n",
            "Epoch: 0004 train_loss= 1.30022 val_ap= 0.66138 time= 2.22530\n",
            "Epoch: 0005 train_loss= 1.31980 val_ap= 0.66224 time= 2.22417\n",
            "Epoch: 0006 train_loss= 1.31054 val_ap= 0.65110 time= 2.19107\n",
            "Epoch: 0007 train_loss= 1.31270 val_ap= 0.63578 time= 2.20643\n",
            "Epoch: 0008 train_loss= 1.31293 val_ap= 0.65967 time= 2.19008\n",
            "Epoch: 0009 train_loss= 1.31571 val_ap= 0.67891 time= 2.20553\n",
            "Epoch: 0010 train_loss= 1.30693 val_ap= 0.65964 time= 2.19536\n",
            "Epoch: 0011 train_loss= 1.30948 val_ap= 0.67099 time= 2.19362\n",
            "Epoch: 0012 train_loss= 1.31479 val_ap= 0.65404 time= 2.17862\n",
            "Epoch: 0013 train_loss= 1.31791 val_ap= 0.66319 time= 2.19327\n",
            "Epoch: 0014 train_loss= 1.31423 val_ap= 0.67503 time= 2.19890\n",
            "Epoch: 0015 train_loss= 1.31570 val_ap= 0.65736 time= 2.22707\n",
            "Epoch: 0016 train_loss= 1.30400 val_ap= 0.64332 time= 2.20515\n",
            "Epoch: 0017 train_loss= 1.30395 val_ap= 0.64480 time= 2.20172\n",
            "Epoch: 0018 train_loss= 1.32137 val_ap= 0.63622 time= 2.19529\n",
            "Epoch: 0019 train_loss= 1.31763 val_ap= 0.65324 time= 2.21299\n",
            "Epoch: 0020 train_loss= 1.31694 val_ap= 0.63492 time= 2.16774\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7335017039982122\n",
            "Test AP score: 0.6415751755271664\n",
            "Settings: 256 8 0.1\n",
            "Epoch: 0001 train_loss= 1.31055 val_ap= 0.65466 time= 2.17020\n",
            "Epoch: 0002 train_loss= 1.32513 val_ap= 0.65079 time= 2.18072\n",
            "Epoch: 0003 train_loss= 1.31623 val_ap= 0.65779 time= 2.16939\n",
            "Epoch: 0004 train_loss= 1.32049 val_ap= 0.65460 time= 2.18795\n",
            "Epoch: 0005 train_loss= 1.31007 val_ap= 0.66182 time= 2.18876\n",
            "Epoch: 0006 train_loss= 1.30349 val_ap= 0.64895 time= 2.17277\n",
            "Epoch: 0007 train_loss= 1.30391 val_ap= 0.64103 time= 2.18486\n",
            "Epoch: 0008 train_loss= 1.32043 val_ap= 0.65936 time= 2.18700\n",
            "Epoch: 0009 train_loss= 1.31008 val_ap= 0.64106 time= 2.22282\n",
            "Epoch: 0010 train_loss= 1.32047 val_ap= 0.65828 time= 2.17383\n",
            "Epoch: 0011 train_loss= 1.30926 val_ap= 0.67980 time= 2.22176\n",
            "Epoch: 0012 train_loss= 1.31967 val_ap= 0.65747 time= 2.22223\n",
            "Epoch: 0013 train_loss= 1.31283 val_ap= 0.65258 time= 2.21928\n",
            "Epoch: 0014 train_loss= 1.31132 val_ap= 0.64705 time= 2.20059\n",
            "Epoch: 0015 train_loss= 1.31009 val_ap= 0.64724 time= 2.18726\n",
            "Epoch: 0016 train_loss= 1.30889 val_ap= 0.68387 time= 2.17812\n",
            "Epoch: 0017 train_loss= 1.31001 val_ap= 0.64190 time= 2.17443\n",
            "Epoch: 0018 train_loss= 1.31187 val_ap= 0.64873 time= 2.16970\n",
            "Epoch: 0019 train_loss= 1.30421 val_ap= 0.66741 time= 2.17894\n",
            "Epoch: 0020 train_loss= 1.32298 val_ap= 0.65925 time= 2.17860\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7508513460680952\n",
            "Test AP score: 0.6636330449609716\n",
            "Settings: 128 64 0.001\n",
            "Epoch: 0001 train_loss= 3.25661 val_ap= 0.65867 time= 2.12987\n",
            "Epoch: 0002 train_loss= 3.24081 val_ap= 0.65497 time= 2.14837\n",
            "Epoch: 0003 train_loss= 3.24224 val_ap= 0.64934 time= 2.14738\n",
            "Epoch: 0004 train_loss= 3.24499 val_ap= 0.65968 time= 2.12318\n",
            "Epoch: 0005 train_loss= 3.26913 val_ap= 0.65217 time= 2.14675\n",
            "Epoch: 0006 train_loss= 3.25679 val_ap= 0.65968 time= 2.14739\n",
            "Epoch: 0007 train_loss= 3.25548 val_ap= 0.65217 time= 2.12223\n",
            "Epoch: 0008 train_loss= 3.25396 val_ap= 0.65371 time= 2.11323\n",
            "Epoch: 0009 train_loss= 3.24997 val_ap= 0.64449 time= 2.14189\n",
            "Epoch: 0010 train_loss= 3.24741 val_ap= 0.64226 time= 2.12089\n",
            "Epoch: 0011 train_loss= 3.24732 val_ap= 0.65232 time= 2.12853\n",
            "Epoch: 0012 train_loss= 3.25598 val_ap= 0.64895 time= 2.13303\n",
            "Epoch: 0013 train_loss= 3.26294 val_ap= 0.64800 time= 2.14706\n",
            "Epoch: 0014 train_loss= 3.25782 val_ap= 0.65389 time= 2.12834\n",
            "Epoch: 0015 train_loss= 3.25312 val_ap= 0.65041 time= 2.12927\n",
            "Epoch: 0016 train_loss= 3.26383 val_ap= 0.64913 time= 2.13524\n",
            "Epoch: 0017 train_loss= 3.25917 val_ap= 0.65658 time= 2.15080\n",
            "Epoch: 0018 train_loss= 3.25887 val_ap= 0.65055 time= 2.13047\n",
            "Epoch: 0019 train_loss= 3.24888 val_ap= 0.65270 time= 2.14082\n",
            "Epoch: 0020 train_loss= 3.25762 val_ap= 0.66055 time= 2.13431\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7509456811804076\n",
            "Test AP score: 0.6705798179970983\n",
            "Settings: 128 64 0.01\n",
            "Epoch: 0001 train_loss= 3.24818 val_ap= 0.65207 time= 2.14652\n",
            "Epoch: 0002 train_loss= 3.26080 val_ap= 0.66257 time= 2.16525\n",
            "Epoch: 0003 train_loss= 3.24769 val_ap= 0.64868 time= 2.14379\n",
            "Epoch: 0004 train_loss= 3.27517 val_ap= 0.65263 time= 2.12313\n",
            "Epoch: 0005 train_loss= 3.27096 val_ap= 0.65345 time= 2.12216\n",
            "Epoch: 0006 train_loss= 3.26275 val_ap= 0.64853 time= 2.15433\n",
            "Epoch: 0007 train_loss= 3.25025 val_ap= 0.64255 time= 2.16935\n",
            "Epoch: 0008 train_loss= 3.25719 val_ap= 0.65010 time= 2.15401\n",
            "Epoch: 0009 train_loss= 3.28032 val_ap= 0.65385 time= 2.14788\n",
            "Epoch: 0010 train_loss= 3.25966 val_ap= 0.65177 time= 2.15331\n",
            "Epoch: 0011 train_loss= 3.24060 val_ap= 0.66065 time= 2.14354\n",
            "Epoch: 0012 train_loss= 3.24579 val_ap= 0.65826 time= 2.12930\n",
            "Epoch: 0013 train_loss= 3.24653 val_ap= 0.65202 time= 2.13862\n",
            "Epoch: 0014 train_loss= 3.26374 val_ap= 0.64955 time= 2.13580\n",
            "Epoch: 0015 train_loss= 3.26760 val_ap= 0.65374 time= 2.14801\n",
            "Epoch: 0016 train_loss= 3.26068 val_ap= 0.65137 time= 2.14069\n",
            "Epoch: 0017 train_loss= 3.24429 val_ap= 0.65784 time= 2.14255\n",
            "Epoch: 0018 train_loss= 3.26344 val_ap= 0.65407 time= 2.14297\n",
            "Epoch: 0019 train_loss= 3.27109 val_ap= 0.64695 time= 2.14212\n",
            "Epoch: 0020 train_loss= 3.25276 val_ap= 0.65301 time= 2.12101\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7444243150793284\n",
            "Test AP score: 0.6603741142017707\n",
            "Settings: 128 64 0.1\n",
            "Epoch: 0001 train_loss= 3.25563 val_ap= 0.65045 time= 2.14331\n",
            "Epoch: 0002 train_loss= 3.25858 val_ap= 0.65052 time= 2.14513\n",
            "Epoch: 0003 train_loss= 3.26848 val_ap= 0.66445 time= 2.13471\n",
            "Epoch: 0004 train_loss= 3.25696 val_ap= 0.64704 time= 2.17713\n",
            "Epoch: 0005 train_loss= 3.24447 val_ap= 0.65209 time= 2.17264\n",
            "Epoch: 0006 train_loss= 3.25253 val_ap= 0.66007 time= 2.18242\n",
            "Epoch: 0007 train_loss= 3.24750 val_ap= 0.64693 time= 2.17352\n",
            "Epoch: 0008 train_loss= 3.26622 val_ap= 0.64753 time= 2.16179\n",
            "Epoch: 0009 train_loss= 3.25215 val_ap= 0.65369 time= 2.10966\n",
            "Epoch: 0010 train_loss= 3.26245 val_ap= 0.64537 time= 2.12366\n",
            "Epoch: 0011 train_loss= 3.25290 val_ap= 0.64559 time= 2.12780\n",
            "Epoch: 0012 train_loss= 3.24783 val_ap= 0.65267 time= 2.12528\n",
            "Epoch: 0013 train_loss= 3.25076 val_ap= 0.65162 time= 2.13099\n",
            "Epoch: 0014 train_loss= 3.26677 val_ap= 0.65131 time= 2.12484\n",
            "Epoch: 0015 train_loss= 3.25086 val_ap= 0.65561 time= 2.14562\n",
            "Epoch: 0016 train_loss= 3.26602 val_ap= 0.64948 time= 2.12169\n",
            "Epoch: 0017 train_loss= 3.25934 val_ap= 0.65549 time= 2.14521\n",
            "Epoch: 0018 train_loss= 3.26336 val_ap= 0.65244 time= 2.13914\n",
            "Epoch: 0019 train_loss= 3.26438 val_ap= 0.65351 time= 2.12067\n",
            "Epoch: 0020 train_loss= 3.24698 val_ap= 0.65327 time= 2.13196\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.74523595688247\n",
            "Test AP score: 0.6614423596497502\n",
            "Settings: 128 32 0.001\n",
            "Epoch: 0001 train_loss= 2.33987 val_ap= 0.65625 time= 1.97781\n",
            "Epoch: 0002 train_loss= 2.34742 val_ap= 0.65769 time= 1.96488\n",
            "Epoch: 0003 train_loss= 2.34618 val_ap= 0.64801 time= 1.98442\n",
            "Epoch: 0004 train_loss= 2.35755 val_ap= 0.66628 time= 1.99604\n",
            "Epoch: 0005 train_loss= 2.36290 val_ap= 0.65879 time= 1.99926\n",
            "Epoch: 0006 train_loss= 2.34895 val_ap= 0.66778 time= 1.99302\n",
            "Epoch: 0007 train_loss= 2.34982 val_ap= 0.66641 time= 2.00227\n",
            "Epoch: 0008 train_loss= 2.34018 val_ap= 0.65441 time= 1.98695\n",
            "Epoch: 0009 train_loss= 2.35619 val_ap= 0.65399 time= 1.97942\n",
            "Epoch: 0010 train_loss= 2.34720 val_ap= 0.65548 time= 1.97503\n",
            "Epoch: 0011 train_loss= 2.34964 val_ap= 0.65032 time= 1.98119\n",
            "Epoch: 0012 train_loss= 2.34173 val_ap= 0.65542 time= 1.96766\n",
            "Epoch: 0013 train_loss= 2.34111 val_ap= 0.65505 time= 1.98024\n",
            "Epoch: 0014 train_loss= 2.35546 val_ap= 0.64718 time= 1.95342\n",
            "Epoch: 0015 train_loss= 2.35407 val_ap= 0.66359 time= 1.96559\n",
            "Epoch: 0016 train_loss= 2.33926 val_ap= 0.66261 time= 1.94694\n",
            "Epoch: 0017 train_loss= 2.35020 val_ap= 0.66374 time= 1.97239\n",
            "Epoch: 0018 train_loss= 2.34744 val_ap= 0.65401 time= 1.96148\n",
            "Epoch: 0019 train_loss= 2.35142 val_ap= 0.64962 time= 1.96904\n",
            "Epoch: 0020 train_loss= 2.34232 val_ap= 0.65801 time= 1.98290\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.747762014408399\n",
            "Test AP score: 0.6653968818003906\n",
            "Settings: 128 32 0.01\n",
            "Epoch: 0001 train_loss= 2.34904 val_ap= 0.64924 time= 1.98118\n",
            "Epoch: 0002 train_loss= 2.35191 val_ap= 0.65132 time= 1.98326\n",
            "Epoch: 0003 train_loss= 2.35062 val_ap= 0.64725 time= 1.97407\n",
            "Epoch: 0004 train_loss= 2.35186 val_ap= 0.64968 time= 1.96748\n",
            "Epoch: 0005 train_loss= 2.34817 val_ap= 0.66618 time= 1.96521\n",
            "Epoch: 0006 train_loss= 2.35213 val_ap= 0.65986 time= 1.93845\n",
            "Epoch: 0007 train_loss= 2.35838 val_ap= 0.65764 time= 1.96046\n",
            "Epoch: 0008 train_loss= 2.36410 val_ap= 0.65362 time= 1.97608\n",
            "Epoch: 0009 train_loss= 2.35584 val_ap= 0.65381 time= 1.95701\n",
            "Epoch: 0010 train_loss= 2.34778 val_ap= 0.64412 time= 1.95317\n",
            "Epoch: 0011 train_loss= 2.34313 val_ap= 0.65136 time= 1.96361\n",
            "Epoch: 0012 train_loss= 2.34500 val_ap= 0.64901 time= 1.97447\n",
            "Epoch: 0013 train_loss= 2.34753 val_ap= 0.64600 time= 1.97192\n",
            "Epoch: 0014 train_loss= 2.35023 val_ap= 0.66799 time= 1.94084\n",
            "Epoch: 0015 train_loss= 2.34752 val_ap= 0.66366 time= 1.97090\n",
            "Epoch: 0016 train_loss= 2.34684 val_ap= 0.66057 time= 1.97460\n",
            "Epoch: 0017 train_loss= 2.34629 val_ap= 0.65809 time= 1.97248\n",
            "Epoch: 0018 train_loss= 2.35357 val_ap= 0.64913 time= 1.96671\n",
            "Epoch: 0019 train_loss= 2.34376 val_ap= 0.64533 time= 1.96597\n",
            "Epoch: 0020 train_loss= 2.35880 val_ap= 0.65266 time= 1.94811\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7439195611449724\n",
            "Test AP score: 0.6584730148207926\n",
            "Settings: 128 32 0.1\n",
            "Epoch: 0001 train_loss= 2.35435 val_ap= 0.66309 time= 1.97035\n",
            "Epoch: 0002 train_loss= 2.34653 val_ap= 0.64840 time= 1.95901\n",
            "Epoch: 0003 train_loss= 2.34809 val_ap= 0.64612 time= 1.98595\n",
            "Epoch: 0004 train_loss= 2.35073 val_ap= 0.66330 time= 1.97132\n",
            "Epoch: 0005 train_loss= 2.34271 val_ap= 0.65111 time= 1.99085\n",
            "Epoch: 0006 train_loss= 2.33824 val_ap= 0.64739 time= 1.97070\n",
            "Epoch: 0007 train_loss= 2.35399 val_ap= 0.65492 time= 1.98911\n",
            "Epoch: 0008 train_loss= 2.36540 val_ap= 0.64204 time= 1.97030\n",
            "Epoch: 0009 train_loss= 2.35883 val_ap= 0.65023 time= 1.98130\n",
            "Epoch: 0010 train_loss= 2.33436 val_ap= 0.64706 time= 1.96278\n",
            "Epoch: 0011 train_loss= 2.34454 val_ap= 0.66071 time= 1.97359\n",
            "Epoch: 0012 train_loss= 2.34104 val_ap= 0.65392 time= 1.97345\n",
            "Epoch: 0013 train_loss= 2.35125 val_ap= 0.64541 time= 1.97021\n",
            "Epoch: 0014 train_loss= 2.34610 val_ap= 0.66355 time= 1.96114\n",
            "Epoch: 0015 train_loss= 2.34379 val_ap= 0.66983 time= 1.98012\n",
            "Epoch: 0016 train_loss= 2.34950 val_ap= 0.65351 time= 1.98482\n",
            "Epoch: 0017 train_loss= 2.36321 val_ap= 0.65750 time= 1.98453\n",
            "Epoch: 0018 train_loss= 2.35478 val_ap= 0.65549 time= 1.98250\n",
            "Epoch: 0019 train_loss= 2.35681 val_ap= 0.65895 time= 1.96994\n",
            "Epoch: 0020 train_loss= 2.33677 val_ap= 0.66070 time= 1.97650\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7509811806804072\n",
            "Test AP score: 0.6688618199111819\n",
            "Settings: 128 16 0.001\n",
            "Epoch: 0001 train_loss= 1.72379 val_ap= 0.65509 time= 1.94545\n",
            "Epoch: 0002 train_loss= 1.71430 val_ap= 0.64833 time= 1.92613\n",
            "Epoch: 0003 train_loss= 1.73286 val_ap= 0.65882 time= 1.91321\n",
            "Epoch: 0004 train_loss= 1.74020 val_ap= 0.65821 time= 1.89809\n",
            "Epoch: 0005 train_loss= 1.73432 val_ap= 0.65013 time= 1.91502\n",
            "Epoch: 0006 train_loss= 1.72959 val_ap= 0.65878 time= 1.91107\n",
            "Epoch: 0007 train_loss= 1.73724 val_ap= 0.64537 time= 1.92036\n",
            "Epoch: 0008 train_loss= 1.72391 val_ap= 0.65549 time= 1.89201\n",
            "Epoch: 0009 train_loss= 1.74683 val_ap= 0.67057 time= 1.91672\n",
            "Epoch: 0010 train_loss= 1.73342 val_ap= 0.65753 time= 1.89762\n",
            "Epoch: 0011 train_loss= 1.72903 val_ap= 0.66286 time= 1.91315\n",
            "Epoch: 0012 train_loss= 1.72272 val_ap= 0.65780 time= 1.92000\n",
            "Epoch: 0013 train_loss= 1.71972 val_ap= 0.66046 time= 1.92114\n",
            "Epoch: 0014 train_loss= 1.72968 val_ap= 0.66295 time= 1.92456\n",
            "Epoch: 0015 train_loss= 1.71769 val_ap= 0.65988 time= 1.93475\n",
            "Epoch: 0016 train_loss= 1.72937 val_ap= 0.66183 time= 1.91081\n",
            "Epoch: 0017 train_loss= 1.73194 val_ap= 0.64490 time= 1.92482\n",
            "Epoch: 0018 train_loss= 1.71325 val_ap= 0.66599 time= 1.90053\n",
            "Epoch: 0019 train_loss= 1.71833 val_ap= 0.65568 time= 1.90533\n",
            "Epoch: 0020 train_loss= 1.72397 val_ap= 0.66827 time= 1.91453\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7575512358717121\n",
            "Test AP score: 0.6733502059566742\n",
            "Settings: 128 16 0.01\n",
            "Epoch: 0001 train_loss= 1.74337 val_ap= 0.65846 time= 1.90782\n",
            "Epoch: 0002 train_loss= 1.73419 val_ap= 0.66402 time= 1.91230\n",
            "Epoch: 0003 train_loss= 1.73978 val_ap= 0.65121 time= 1.91920\n",
            "Epoch: 0004 train_loss= 1.73229 val_ap= 0.65822 time= 1.90397\n",
            "Epoch: 0005 train_loss= 1.72848 val_ap= 0.64881 time= 1.96124\n",
            "Epoch: 0006 train_loss= 1.70859 val_ap= 0.65180 time= 1.92499\n",
            "Epoch: 0007 train_loss= 1.73238 val_ap= 0.65673 time= 1.92253\n",
            "Epoch: 0008 train_loss= 1.73834 val_ap= 0.64763 time= 1.92067\n",
            "Epoch: 0009 train_loss= 1.73044 val_ap= 0.65829 time= 1.93566\n",
            "Epoch: 0010 train_loss= 1.72939 val_ap= 0.66685 time= 1.91193\n",
            "Epoch: 0011 train_loss= 1.73853 val_ap= 0.66337 time= 1.90994\n",
            "Epoch: 0012 train_loss= 1.73575 val_ap= 0.63919 time= 1.88808\n",
            "Epoch: 0013 train_loss= 1.72341 val_ap= 0.64351 time= 1.90558\n",
            "Epoch: 0014 train_loss= 1.71870 val_ap= 0.66890 time= 1.91345\n",
            "Epoch: 0015 train_loss= 1.73232 val_ap= 0.63653 time= 1.88406\n",
            "Epoch: 0016 train_loss= 1.72548 val_ap= 0.66705 time= 1.89785\n",
            "Epoch: 0017 train_loss= 1.73330 val_ap= 0.66947 time= 1.90824\n",
            "Epoch: 0018 train_loss= 1.73189 val_ap= 0.65855 time= 1.90458\n",
            "Epoch: 0019 train_loss= 1.73219 val_ap= 0.67206 time= 1.92209\n",
            "Epoch: 0020 train_loss= 1.72104 val_ap= 0.65135 time= 1.89455\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7472329870078938\n",
            "Test AP score: 0.6601869905853862\n",
            "Settings: 128 16 0.1\n",
            "Epoch: 0001 train_loss= 1.74413 val_ap= 0.65300 time= 1.91890\n",
            "Epoch: 0002 train_loss= 1.73185 val_ap= 0.65670 time= 1.88458\n",
            "Epoch: 0003 train_loss= 1.72138 val_ap= 0.64880 time= 1.96244\n",
            "Epoch: 0004 train_loss= 1.72994 val_ap= 0.66316 time= 1.91922\n",
            "Epoch: 0005 train_loss= 1.73513 val_ap= 0.66012 time= 1.90906\n",
            "Epoch: 0006 train_loss= 1.72993 val_ap= 0.65407 time= 1.89943\n",
            "Epoch: 0007 train_loss= 1.72621 val_ap= 0.66174 time= 1.89554\n",
            "Epoch: 0008 train_loss= 1.72489 val_ap= 0.65863 time= 1.90650\n",
            "Epoch: 0009 train_loss= 1.73960 val_ap= 0.66597 time= 1.90032\n",
            "Epoch: 0010 train_loss= 1.73892 val_ap= 0.64855 time= 1.90675\n",
            "Epoch: 0011 train_loss= 1.72333 val_ap= 0.65355 time= 1.89968\n",
            "Epoch: 0012 train_loss= 1.72335 val_ap= 0.66657 time= 1.90630\n",
            "Epoch: 0013 train_loss= 1.73215 val_ap= 0.66871 time= 1.92561\n",
            "Epoch: 0014 train_loss= 1.73619 val_ap= 0.65451 time= 1.92205\n",
            "Epoch: 0015 train_loss= 1.72309 val_ap= 0.65422 time= 1.89901\n",
            "Epoch: 0016 train_loss= 1.71193 val_ap= 0.66463 time= 1.90380\n",
            "Epoch: 0017 train_loss= 1.72223 val_ap= 0.64881 time= 1.89559\n",
            "Epoch: 0018 train_loss= 1.72294 val_ap= 0.66303 time= 1.88860\n",
            "Epoch: 0019 train_loss= 1.73142 val_ap= 0.66859 time= 1.91582\n",
            "Epoch: 0020 train_loss= 1.73301 val_ap= 0.64433 time= 1.90480\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7418201639843227\n",
            "Test AP score: 0.6528830779857604\n",
            "Settings: 128 8 0.001\n",
            "Epoch: 0001 train_loss= 1.30347 val_ap= 0.65564 time= 1.92813\n",
            "Epoch: 0002 train_loss= 1.32022 val_ap= 0.64839 time= 1.89603\n",
            "Epoch: 0003 train_loss= 1.30914 val_ap= 0.66258 time= 1.89841\n",
            "Epoch: 0004 train_loss= 1.31372 val_ap= 0.65450 time= 1.87821\n",
            "Epoch: 0005 train_loss= 1.30277 val_ap= 0.67012 time= 1.91618\n",
            "Epoch: 0006 train_loss= 1.32335 val_ap= 0.63915 time= 1.93493\n",
            "Epoch: 0007 train_loss= 1.31355 val_ap= 0.63662 time= 1.92172\n",
            "Epoch: 0008 train_loss= 1.31560 val_ap= 0.64679 time= 1.91472\n",
            "Epoch: 0009 train_loss= 1.32861 val_ap= 0.65552 time= 1.93070\n",
            "Epoch: 0010 train_loss= 1.31181 val_ap= 0.65819 time= 1.93011\n",
            "Epoch: 0011 train_loss= 1.31120 val_ap= 0.63799 time= 1.94174\n",
            "Epoch: 0012 train_loss= 1.31521 val_ap= 0.68086 time= 1.90584\n",
            "Epoch: 0013 train_loss= 1.31616 val_ap= 0.63204 time= 1.87948\n",
            "Epoch: 0014 train_loss= 1.31439 val_ap= 0.64753 time= 1.94146\n",
            "Epoch: 0015 train_loss= 1.31050 val_ap= 0.65152 time= 1.91210\n",
            "Epoch: 0016 train_loss= 1.31301 val_ap= 0.64219 time= 1.89762\n",
            "Epoch: 0017 train_loss= 1.30841 val_ap= 0.67166 time= 1.96465\n",
            "Epoch: 0018 train_loss= 1.32003 val_ap= 0.66408 time= 1.86899\n",
            "Epoch: 0019 train_loss= 1.31184 val_ap= 0.67402 time= 1.95949\n",
            "Epoch: 0020 train_loss= 1.31482 val_ap= 0.66076 time= 1.91442\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7542131322810348\n",
            "Test AP score: 0.6708738244965806\n",
            "Settings: 128 8 0.01\n",
            "Epoch: 0001 train_loss= 1.32019 val_ap= 0.67674 time= 1.90950\n",
            "Epoch: 0002 train_loss= 1.33101 val_ap= 0.64818 time= 1.91382\n",
            "Epoch: 0003 train_loss= 1.33067 val_ap= 0.65733 time= 1.92988\n",
            "Epoch: 0004 train_loss= 1.31128 val_ap= 0.65070 time= 1.92571\n",
            "Epoch: 0005 train_loss= 1.31797 val_ap= 0.63132 time= 1.90047\n",
            "Epoch: 0006 train_loss= 1.32384 val_ap= 0.65745 time= 1.88459\n",
            "Epoch: 0007 train_loss= 1.31594 val_ap= 0.66209 time= 1.89146\n",
            "Epoch: 0008 train_loss= 1.31580 val_ap= 0.65302 time= 1.89410\n",
            "Epoch: 0009 train_loss= 1.31792 val_ap= 0.64344 time= 1.90540\n",
            "Epoch: 0010 train_loss= 1.30578 val_ap= 0.66018 time= 1.89104\n",
            "Epoch: 0011 train_loss= 1.31788 val_ap= 0.64326 time= 1.90194\n",
            "Epoch: 0012 train_loss= 1.32803 val_ap= 0.66451 time= 1.90293\n",
            "Epoch: 0013 train_loss= 1.31981 val_ap= 0.65578 time= 1.88007\n",
            "Epoch: 0014 train_loss= 1.30528 val_ap= 0.64100 time= 1.88999\n",
            "Epoch: 0015 train_loss= 1.30744 val_ap= 0.67204 time= 1.89169\n",
            "Epoch: 0016 train_loss= 1.31672 val_ap= 0.66441 time= 1.87882\n",
            "Epoch: 0017 train_loss= 1.30510 val_ap= 0.65389 time= 1.90569\n",
            "Epoch: 0018 train_loss= 1.32034 val_ap= 0.67078 time= 1.89548\n",
            "Epoch: 0019 train_loss= 1.31135 val_ap= 0.66484 time= 1.91924\n",
            "Epoch: 0020 train_loss= 1.31703 val_ap= 0.65784 time= 1.90919\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.753187094110796\n",
            "Test AP score: 0.6657435107284904\n",
            "Settings: 128 8 0.1\n",
            "Epoch: 0001 train_loss= 1.31792 val_ap= 0.68072 time= 1.91405\n",
            "Epoch: 0002 train_loss= 1.30983 val_ap= 0.65659 time= 1.89929\n",
            "Epoch: 0003 train_loss= 1.31327 val_ap= 0.66378 time= 1.90098\n",
            "Epoch: 0004 train_loss= 1.31415 val_ap= 0.64933 time= 1.88973\n",
            "Epoch: 0005 train_loss= 1.32394 val_ap= 0.65851 time= 1.95858\n",
            "Epoch: 0006 train_loss= 1.30759 val_ap= 0.67851 time= 1.90470\n",
            "Epoch: 0007 train_loss= 1.30854 val_ap= 0.65103 time= 1.92546\n",
            "Epoch: 0008 train_loss= 1.31169 val_ap= 0.65239 time= 1.91643\n",
            "Epoch: 0009 train_loss= 1.30737 val_ap= 0.65530 time= 1.92552\n",
            "Epoch: 0010 train_loss= 1.30381 val_ap= 0.66331 time= 1.92673\n",
            "Epoch: 0011 train_loss= 1.30997 val_ap= 0.65991 time= 1.92196\n",
            "Epoch: 0012 train_loss= 1.32222 val_ap= 0.66771 time= 1.91013\n",
            "Epoch: 0013 train_loss= 1.30801 val_ap= 0.63241 time= 1.89539\n",
            "Epoch: 0014 train_loss= 1.31177 val_ap= 0.66480 time= 1.91438\n",
            "Epoch: 0015 train_loss= 1.30211 val_ap= 0.66899 time= 1.91233\n",
            "Epoch: 0016 train_loss= 1.31291 val_ap= 0.65606 time= 1.90423\n",
            "Epoch: 0017 train_loss= 1.33328 val_ap= 0.65509 time= 1.92055\n",
            "Epoch: 0018 train_loss= 1.31220 val_ap= 0.66542 time= 1.90996\n",
            "Epoch: 0019 train_loss= 1.31828 val_ap= 0.66212 time= 1.92675\n",
            "Epoch: 0020 train_loss= 1.30809 val_ap= 0.65131 time= 1.90579\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7463650017986088\n",
            "Test AP score: 0.6579948533373554\n",
            "Settings: 64 64 0.001\n",
            "Epoch: 0001 train_loss= 3.25723 val_ap= 0.65100 time= 1.99564\n",
            "Epoch: 0002 train_loss= 3.26624 val_ap= 0.65294 time= 2.00200\n",
            "Epoch: 0003 train_loss= 3.25756 val_ap= 0.65680 time= 1.99230\n",
            "Epoch: 0004 train_loss= 3.24017 val_ap= 0.65451 time= 2.00101\n",
            "Epoch: 0005 train_loss= 3.25053 val_ap= 0.64763 time= 2.00810\n",
            "Epoch: 0006 train_loss= 3.24515 val_ap= 0.66140 time= 2.00388\n",
            "Epoch: 0007 train_loss= 3.25201 val_ap= 0.65618 time= 2.01472\n",
            "Epoch: 0008 train_loss= 3.25337 val_ap= 0.64563 time= 2.00455\n",
            "Epoch: 0009 train_loss= 3.24945 val_ap= 0.64968 time= 2.01338\n",
            "Epoch: 0010 train_loss= 3.26508 val_ap= 0.65004 time= 1.99267\n",
            "Epoch: 0011 train_loss= 3.24702 val_ap= 0.66019 time= 1.99514\n",
            "Epoch: 0012 train_loss= 3.23878 val_ap= 0.64519 time= 1.98791\n",
            "Epoch: 0013 train_loss= 3.26220 val_ap= 0.64246 time= 1.99261\n",
            "Epoch: 0014 train_loss= 3.23943 val_ap= 0.64517 time= 2.00832\n",
            "Epoch: 0015 train_loss= 3.26792 val_ap= 0.65909 time= 2.04914\n",
            "Epoch: 0016 train_loss= 3.24662 val_ap= 0.65347 time= 2.01854\n",
            "Epoch: 0017 train_loss= 3.25657 val_ap= 0.66545 time= 2.01934\n",
            "Epoch: 0018 train_loss= 3.24648 val_ap= 0.65205 time= 1.99000\n",
            "Epoch: 0019 train_loss= 3.24249 val_ap= 0.66321 time= 1.99998\n",
            "Epoch: 0020 train_loss= 3.24886 val_ap= 0.64901 time= 2.00605\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.741679765261011\n",
            "Test AP score: 0.6570372152949259\n",
            "Settings: 64 64 0.01\n",
            "Epoch: 0001 train_loss= 3.24251 val_ap= 0.66096 time= 2.00743\n",
            "Epoch: 0002 train_loss= 3.27417 val_ap= 0.66348 time= 1.98774\n",
            "Epoch: 0003 train_loss= 3.24377 val_ap= 0.64942 time= 1.98997\n",
            "Epoch: 0004 train_loss= 3.25481 val_ap= 0.64443 time= 1.99893\n",
            "Epoch: 0005 train_loss= 3.27138 val_ap= 0.64757 time= 2.00848\n",
            "Epoch: 0006 train_loss= 3.25081 val_ap= 0.65520 time= 2.01391\n",
            "Epoch: 0007 train_loss= 3.27035 val_ap= 0.65041 time= 2.02190\n",
            "Epoch: 0008 train_loss= 3.24549 val_ap= 0.66023 time= 2.01177\n",
            "Epoch: 0009 train_loss= 3.26144 val_ap= 0.65519 time= 2.02526\n",
            "Epoch: 0010 train_loss= 3.24934 val_ap= 0.64881 time= 2.01948\n",
            "Epoch: 0011 train_loss= 3.24998 val_ap= 0.65533 time= 2.04525\n",
            "Epoch: 0012 train_loss= 3.25533 val_ap= 0.64789 time= 2.00522\n",
            "Epoch: 0013 train_loss= 3.24072 val_ap= 0.64967 time= 2.01254\n",
            "Epoch: 0014 train_loss= 3.24584 val_ap= 0.64731 time= 2.01683\n",
            "Epoch: 0015 train_loss= 3.26126 val_ap= 0.63804 time= 2.04525\n",
            "Epoch: 0016 train_loss= 3.25377 val_ap= 0.65177 time= 2.02217\n",
            "Epoch: 0017 train_loss= 3.24984 val_ap= 0.65650 time= 2.04836\n",
            "Epoch: 0018 train_loss= 3.26189 val_ap= 0.65226 time= 2.01891\n",
            "Epoch: 0019 train_loss= 3.25093 val_ap= 0.65220 time= 2.00890\n",
            "Epoch: 0020 train_loss= 3.26007 val_ap= 0.64938 time= 2.03498\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.742868294385008\n",
            "Test AP score: 0.6572321908506475\n",
            "Settings: 64 64 0.1\n",
            "Epoch: 0001 train_loss= 3.26941 val_ap= 0.66050 time= 2.00864\n",
            "Epoch: 0002 train_loss= 3.27420 val_ap= 0.65332 time= 1.99698\n",
            "Epoch: 0003 train_loss= 3.24851 val_ap= 0.65061 time= 2.00664\n",
            "Epoch: 0004 train_loss= 3.26304 val_ap= 0.64224 time= 2.02171\n",
            "Epoch: 0005 train_loss= 3.27273 val_ap= 0.65792 time= 2.00569\n",
            "Epoch: 0006 train_loss= 3.25191 val_ap= 0.65498 time= 2.00329\n",
            "Epoch: 0007 train_loss= 3.25935 val_ap= 0.65349 time= 2.00214\n",
            "Epoch: 0008 train_loss= 3.25291 val_ap= 0.65478 time= 1.99963\n",
            "Epoch: 0009 train_loss= 3.24863 val_ap= 0.67204 time= 1.98832\n",
            "Epoch: 0010 train_loss= 3.26740 val_ap= 0.64738 time= 1.98078\n",
            "Epoch: 0011 train_loss= 3.25773 val_ap= 0.65278 time= 1.99928\n",
            "Epoch: 0012 train_loss= 3.26256 val_ap= 0.64994 time= 1.98597\n",
            "Epoch: 0013 train_loss= 3.24831 val_ap= 0.65452 time= 1.98571\n",
            "Epoch: 0014 train_loss= 3.24929 val_ap= 0.64985 time= 2.00092\n",
            "Epoch: 0015 train_loss= 3.25604 val_ap= 0.64614 time= 1.99755\n",
            "Epoch: 0016 train_loss= 3.24895 val_ap= 0.65261 time= 1.99890\n",
            "Epoch: 0017 train_loss= 3.26007 val_ap= 0.64796 time= 1.98451\n",
            "Epoch: 0018 train_loss= 3.25964 val_ap= 0.65357 time= 1.98354\n",
            "Epoch: 0019 train_loss= 3.27148 val_ap= 0.66094 time= 2.02778\n",
            "Epoch: 0020 train_loss= 3.25836 val_ap= 0.65187 time= 1.98144\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7429904968935783\n",
            "Test AP score: 0.6580413144082883\n",
            "Settings: 64 32 0.001\n",
            "Epoch: 0001 train_loss= 2.34469 val_ap= 0.65647 time= 1.85842\n",
            "Epoch: 0002 train_loss= 2.35752 val_ap= 0.63942 time= 1.85206\n",
            "Epoch: 0003 train_loss= 2.36154 val_ap= 0.65707 time= 1.86199\n",
            "Epoch: 0004 train_loss= 2.36038 val_ap= 0.66223 time= 1.87726\n",
            "Epoch: 0005 train_loss= 2.35438 val_ap= 0.64843 time= 1.85960\n",
            "Epoch: 0006 train_loss= 2.33875 val_ap= 0.65068 time= 1.83179\n",
            "Epoch: 0007 train_loss= 2.35053 val_ap= 0.64747 time= 1.87386\n",
            "Epoch: 0008 train_loss= 2.35273 val_ap= 0.65260 time= 1.84529\n",
            "Epoch: 0009 train_loss= 2.34217 val_ap= 0.65293 time= 1.87544\n",
            "Epoch: 0010 train_loss= 2.33860 val_ap= 0.65252 time= 1.85524\n",
            "Epoch: 0011 train_loss= 2.35828 val_ap= 0.64083 time= 1.88546\n",
            "Epoch: 0012 train_loss= 2.35064 val_ap= 0.65828 time= 1.84955\n",
            "Epoch: 0013 train_loss= 2.33798 val_ap= 0.65819 time= 1.86949\n",
            "Epoch: 0014 train_loss= 2.34237 val_ap= 0.64559 time= 1.82910\n",
            "Epoch: 0015 train_loss= 2.36091 val_ap= 0.66045 time= 1.84861\n",
            "Epoch: 0016 train_loss= 2.35490 val_ap= 0.65399 time= 1.83962\n",
            "Epoch: 0017 train_loss= 2.34849 val_ap= 0.65606 time= 1.85837\n",
            "Epoch: 0018 train_loss= 2.35732 val_ap= 0.66349 time= 1.84524\n",
            "Epoch: 0019 train_loss= 2.35584 val_ap= 0.65304 time= 1.83292\n",
            "Epoch: 0020 train_loss= 2.36519 val_ap= 0.64817 time= 1.84414\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7430732150377394\n",
            "Test AP score: 0.6553965490745779\n",
            "Settings: 64 32 0.01\n",
            "Epoch: 0001 train_loss= 2.35903 val_ap= 0.65286 time= 1.83994\n",
            "Epoch: 0002 train_loss= 2.34982 val_ap= 0.66164 time= 1.83745\n",
            "Epoch: 0003 train_loss= 2.32678 val_ap= 0.68156 time= 1.84838\n",
            "Epoch: 0004 train_loss= 2.33624 val_ap= 0.65544 time= 1.83113\n",
            "Epoch: 0005 train_loss= 2.34961 val_ap= 0.65571 time= 1.83282\n",
            "Epoch: 0006 train_loss= 2.34582 val_ap= 0.65307 time= 1.85379\n",
            "Epoch: 0007 train_loss= 2.35395 val_ap= 0.65252 time= 1.85645\n",
            "Epoch: 0008 train_loss= 2.36478 val_ap= 0.65283 time= 1.82877\n",
            "Epoch: 0009 train_loss= 2.34438 val_ap= 0.65228 time= 1.83691\n",
            "Epoch: 0010 train_loss= 2.35631 val_ap= 0.67312 time= 1.83010\n",
            "Epoch: 0011 train_loss= 2.35463 val_ap= 0.66632 time= 1.86441\n",
            "Epoch: 0012 train_loss= 2.34403 val_ap= 0.65792 time= 1.82983\n",
            "Epoch: 0013 train_loss= 2.33606 val_ap= 0.65226 time= 1.82856\n",
            "Epoch: 0014 train_loss= 2.34604 val_ap= 0.64686 time= 1.82660\n",
            "Epoch: 0015 train_loss= 2.34572 val_ap= 0.66281 time= 1.84583\n",
            "Epoch: 0016 train_loss= 2.35030 val_ap= 0.65236 time= 1.84659\n",
            "Epoch: 0017 train_loss= 2.35187 val_ap= 0.65460 time= 1.92724\n",
            "Epoch: 0018 train_loss= 2.35763 val_ap= 0.65649 time= 1.86898\n",
            "Epoch: 0019 train_loss= 2.34391 val_ap= 0.65091 time= 1.91007\n",
            "Epoch: 0020 train_loss= 2.33891 val_ap= 0.65876 time= 1.85326\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7477704594777894\n",
            "Test AP score: 0.6649613201579132\n",
            "Settings: 64 32 0.1\n",
            "Epoch: 0001 train_loss= 2.35121 val_ap= 0.64727 time= 1.88517\n",
            "Epoch: 0002 train_loss= 2.34900 val_ap= 0.65601 time= 1.83945\n",
            "Epoch: 0003 train_loss= 2.36008 val_ap= 0.65809 time= 1.86410\n",
            "Epoch: 0004 train_loss= 2.36695 val_ap= 0.65909 time= 1.86159\n",
            "Epoch: 0005 train_loss= 2.35398 val_ap= 0.65793 time= 1.86547\n",
            "Epoch: 0006 train_loss= 2.34853 val_ap= 0.66410 time= 1.84030\n",
            "Epoch: 0007 train_loss= 2.34405 val_ap= 0.65075 time= 1.85239\n",
            "Epoch: 0008 train_loss= 2.35622 val_ap= 0.65183 time= 1.85985\n",
            "Epoch: 0009 train_loss= 2.35945 val_ap= 0.64852 time= 1.85536\n",
            "Epoch: 0010 train_loss= 2.36018 val_ap= 0.65012 time= 1.92446\n",
            "Epoch: 0011 train_loss= 2.32777 val_ap= 0.65288 time= 1.84678\n",
            "Epoch: 0012 train_loss= 2.37533 val_ap= 0.65037 time= 1.84222\n",
            "Epoch: 0013 train_loss= 2.37137 val_ap= 0.65503 time= 1.86335\n",
            "Epoch: 0014 train_loss= 2.34407 val_ap= 0.64999 time= 1.85487\n",
            "Epoch: 0015 train_loss= 2.36287 val_ap= 0.66069 time= 1.84732\n",
            "Epoch: 0016 train_loss= 2.34699 val_ap= 0.66358 time= 1.81665\n",
            "Epoch: 0017 train_loss= 2.36192 val_ap= 0.65003 time= 1.82920\n",
            "Epoch: 0018 train_loss= 2.34953 val_ap= 0.65416 time= 1.84639\n",
            "Epoch: 0019 train_loss= 2.33422 val_ap= 0.65788 time= 1.86234\n",
            "Epoch: 0020 train_loss= 2.34458 val_ap= 0.66719 time= 1.85213\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7549414873083047\n",
            "Test AP score: 0.6745376513911354\n",
            "Settings: 64 16 0.001\n",
            "Epoch: 0001 train_loss= 1.72489 val_ap= 0.64239 time= 1.79514\n",
            "Epoch: 0002 train_loss= 1.72941 val_ap= 0.65915 time= 1.81769\n",
            "Epoch: 0003 train_loss= 1.72921 val_ap= 0.66534 time= 1.82152\n",
            "Epoch: 0004 train_loss= 1.74747 val_ap= 0.65732 time= 1.79126\n",
            "Epoch: 0005 train_loss= 1.73972 val_ap= 0.65054 time= 1.78806\n",
            "Epoch: 0006 train_loss= 1.72041 val_ap= 0.64629 time= 1.79854\n",
            "Epoch: 0007 train_loss= 1.72323 val_ap= 0.65995 time= 1.78748\n",
            "Epoch: 0008 train_loss= 1.72935 val_ap= 0.66867 time= 1.79973\n",
            "Epoch: 0009 train_loss= 1.71071 val_ap= 0.65782 time= 1.81924\n",
            "Epoch: 0010 train_loss= 1.72954 val_ap= 0.65149 time= 1.78565\n",
            "Epoch: 0011 train_loss= 1.71976 val_ap= 0.67055 time= 1.80220\n",
            "Epoch: 0012 train_loss= 1.71730 val_ap= 0.66087 time= 1.80109\n",
            "Epoch: 0013 train_loss= 1.73772 val_ap= 0.66150 time= 1.79925\n",
            "Epoch: 0014 train_loss= 1.73451 val_ap= 0.65536 time= 1.78255\n",
            "Epoch: 0015 train_loss= 1.72702 val_ap= 0.64865 time= 1.80579\n",
            "Epoch: 0016 train_loss= 1.71686 val_ap= 0.63685 time= 1.78023\n",
            "Epoch: 0017 train_loss= 1.73274 val_ap= 0.65610 time= 1.80452\n",
            "Epoch: 0018 train_loss= 1.72444 val_ap= 0.64493 time= 1.78284\n",
            "Epoch: 0019 train_loss= 1.72591 val_ap= 0.67461 time= 1.84855\n",
            "Epoch: 0020 train_loss= 1.73234 val_ap= 0.65860 time= 1.80648\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7494160130119285\n",
            "Test AP score: 0.6662293605904971\n",
            "Settings: 64 16 0.01\n",
            "Epoch: 0001 train_loss= 1.72601 val_ap= 0.66772 time= 1.79219\n",
            "Epoch: 0002 train_loss= 1.72769 val_ap= 0.67208 time= 1.76745\n",
            "Epoch: 0003 train_loss= 1.73243 val_ap= 0.66307 time= 1.79730\n",
            "Epoch: 0004 train_loss= 1.71229 val_ap= 0.64757 time= 1.77241\n",
            "Epoch: 0005 train_loss= 1.73049 val_ap= 0.66601 time= 1.79513\n",
            "Epoch: 0006 train_loss= 1.71924 val_ap= 0.64585 time= 1.77923\n",
            "Epoch: 0007 train_loss= 1.72821 val_ap= 0.66793 time= 1.79363\n",
            "Epoch: 0008 train_loss= 1.73568 val_ap= 0.65196 time= 1.76552\n",
            "Epoch: 0009 train_loss= 1.72818 val_ap= 0.64705 time= 1.79172\n",
            "Epoch: 0010 train_loss= 1.72931 val_ap= 0.65997 time= 1.77630\n",
            "Epoch: 0011 train_loss= 1.73713 val_ap= 0.65127 time= 1.77539\n",
            "Epoch: 0012 train_loss= 1.71995 val_ap= 0.64106 time= 1.77658\n",
            "Epoch: 0013 train_loss= 1.74122 val_ap= 0.66054 time= 1.80114\n",
            "Epoch: 0014 train_loss= 1.72915 val_ap= 0.67407 time= 1.78786\n",
            "Epoch: 0015 train_loss= 1.71981 val_ap= 0.65421 time= 1.80378\n",
            "Epoch: 0016 train_loss= 1.72825 val_ap= 0.65979 time= 1.77917\n",
            "Epoch: 0017 train_loss= 1.73909 val_ap= 0.66172 time= 1.82157\n",
            "Epoch: 0018 train_loss= 1.73326 val_ap= 0.66096 time= 1.79546\n",
            "Epoch: 0019 train_loss= 1.71800 val_ap= 0.65669 time= 1.80141\n",
            "Epoch: 0020 train_loss= 1.73158 val_ap= 0.65703 time= 1.77351\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7486707234215253\n",
            "Test AP score: 0.663593109269808\n",
            "Settings: 64 16 0.1\n",
            "Epoch: 0001 train_loss= 1.71667 val_ap= 0.65929 time= 1.77809\n",
            "Epoch: 0002 train_loss= 1.72587 val_ap= 0.66924 time= 1.77858\n",
            "Epoch: 0003 train_loss= 1.73061 val_ap= 0.64654 time= 1.79109\n",
            "Epoch: 0004 train_loss= 1.73799 val_ap= 0.65633 time= 1.78208\n",
            "Epoch: 0005 train_loss= 1.73912 val_ap= 0.64988 time= 1.78540\n",
            "Epoch: 0006 train_loss= 1.74465 val_ap= 0.66886 time= 1.79043\n",
            "Epoch: 0007 train_loss= 1.73325 val_ap= 0.65506 time= 1.78607\n",
            "Epoch: 0008 train_loss= 1.72606 val_ap= 0.66615 time= 1.78429\n",
            "Epoch: 0009 train_loss= 1.73090 val_ap= 0.66570 time= 1.80197\n",
            "Epoch: 0010 train_loss= 1.73207 val_ap= 0.66278 time= 1.80793\n",
            "Epoch: 0011 train_loss= 1.71007 val_ap= 0.65850 time= 1.80597\n",
            "Epoch: 0012 train_loss= 1.72446 val_ap= 0.64146 time= 1.84048\n",
            "Epoch: 0013 train_loss= 1.73152 val_ap= 0.66582 time= 1.81923\n",
            "Epoch: 0014 train_loss= 1.73462 val_ap= 0.64098 time= 1.79630\n",
            "Epoch: 0015 train_loss= 1.72482 val_ap= 0.64493 time= 1.81483\n",
            "Epoch: 0016 train_loss= 1.73220 val_ap= 0.67707 time= 1.85044\n",
            "Epoch: 0017 train_loss= 1.71028 val_ap= 0.65214 time= 1.81439\n",
            "Epoch: 0018 train_loss= 1.73939 val_ap= 0.65369 time= 1.79871\n",
            "Epoch: 0019 train_loss= 1.72614 val_ap= 0.65631 time= 1.80365\n",
            "Epoch: 0020 train_loss= 1.71667 val_ap= 0.66407 time= 1.79776\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7531903593006972\n",
            "Test AP score: 0.6738538589845108\n",
            "Settings: 64 8 0.001\n",
            "Epoch: 0001 train_loss= 1.30719 val_ap= 0.66367 time= 2.01492\n",
            "Epoch: 0002 train_loss= 1.30552 val_ap= 0.64461 time= 1.82335\n",
            "Epoch: 0003 train_loss= 1.31228 val_ap= 0.68484 time= 1.81460\n",
            "Epoch: 0004 train_loss= 1.31273 val_ap= 0.67019 time= 1.81853\n",
            "Epoch: 0005 train_loss= 1.30381 val_ap= 0.64216 time= 1.83857\n",
            "Epoch: 0006 train_loss= 1.31136 val_ap= 0.65528 time= 1.84225\n",
            "Epoch: 0007 train_loss= 1.32378 val_ap= 0.66483 time= 1.81659\n",
            "Epoch: 0008 train_loss= 1.30771 val_ap= 0.66885 time= 1.79068\n",
            "Epoch: 0009 train_loss= 1.30553 val_ap= 0.66548 time= 1.81790\n",
            "Epoch: 0010 train_loss= 1.30679 val_ap= 0.64850 time= 1.81712\n",
            "Epoch: 0011 train_loss= 1.31243 val_ap= 0.67543 time= 1.81647\n",
            "Epoch: 0012 train_loss= 1.30906 val_ap= 0.65667 time= 1.85378\n",
            "Epoch: 0013 train_loss= 1.30845 val_ap= 0.65079 time= 1.81971\n",
            "Epoch: 0014 train_loss= 1.31336 val_ap= 0.66138 time= 1.82027\n",
            "Epoch: 0015 train_loss= 1.30904 val_ap= 0.64964 time= 1.82897\n",
            "Epoch: 0016 train_loss= 1.31941 val_ap= 0.67868 time= 1.84127\n",
            "Epoch: 0017 train_loss= 1.31201 val_ap= 0.67871 time= 1.83257\n",
            "Epoch: 0018 train_loss= 1.31465 val_ap= 0.66193 time= 1.85814\n",
            "Epoch: 0019 train_loss= 1.30161 val_ap= 0.65005 time= 1.85769\n",
            "Epoch: 0020 train_loss= 1.31975 val_ap= 0.66550 time= 1.83395\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7551519387929092\n",
            "Test AP score: 0.6707021319711336\n",
            "Settings: 64 8 0.01\n",
            "Epoch: 0001 train_loss= 1.32102 val_ap= 0.65715 time= 1.86788\n",
            "Epoch: 0002 train_loss= 1.32681 val_ap= 0.67701 time= 1.81561\n",
            "Epoch: 0003 train_loss= 1.30678 val_ap= 0.68318 time= 1.84136\n",
            "Epoch: 0004 train_loss= 1.31687 val_ap= 0.63757 time= 1.86547\n",
            "Epoch: 0005 train_loss= 1.30852 val_ap= 0.67144 time= 1.81246\n",
            "Epoch: 0006 train_loss= 1.30506 val_ap= 0.66581 time= 1.82467\n",
            "Epoch: 0007 train_loss= 1.31020 val_ap= 0.65336 time= 1.82853\n",
            "Epoch: 0008 train_loss= 1.31599 val_ap= 0.64673 time= 1.81103\n",
            "Epoch: 0009 train_loss= 1.31917 val_ap= 0.67149 time= 1.82564\n",
            "Epoch: 0010 train_loss= 1.30879 val_ap= 0.64813 time= 1.81519\n",
            "Epoch: 0011 train_loss= 1.32115 val_ap= 0.66662 time= 1.82487\n",
            "Epoch: 0012 train_loss= 1.31536 val_ap= 0.66608 time= 1.81927\n",
            "Epoch: 0013 train_loss= 1.31379 val_ap= 0.66188 time= 1.80471\n",
            "Epoch: 0014 train_loss= 1.31723 val_ap= 0.64120 time= 1.80573\n",
            "Epoch: 0015 train_loss= 1.31918 val_ap= 0.66373 time= 1.82243\n",
            "Epoch: 0016 train_loss= 1.30764 val_ap= 0.65462 time= 1.80359\n",
            "Epoch: 0017 train_loss= 1.30687 val_ap= 0.65486 time= 1.83192\n",
            "Epoch: 0018 train_loss= 1.31428 val_ap= 0.64537 time= 1.80435\n",
            "Epoch: 0019 train_loss= 1.30771 val_ap= 0.66499 time= 1.81165\n",
            "Epoch: 0020 train_loss= 1.31209 val_ap= 0.65084 time= 1.81229\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7516716284077776\n",
            "Test AP score: 0.6575414315987373\n",
            "Settings: 64 8 0.1\n",
            "Epoch: 0001 train_loss= 1.31616 val_ap= 0.66100 time= 1.79776\n",
            "Epoch: 0002 train_loss= 1.31861 val_ap= 0.66867 time= 1.81090\n",
            "Epoch: 0003 train_loss= 1.30969 val_ap= 0.69071 time= 1.80182\n",
            "Epoch: 0004 train_loss= 1.30537 val_ap= 0.64306 time= 1.79939\n",
            "Epoch: 0005 train_loss= 1.31656 val_ap= 0.65617 time= 1.80127\n",
            "Epoch: 0006 train_loss= 1.31917 val_ap= 0.67351 time= 1.79228\n",
            "Epoch: 0007 train_loss= 1.31770 val_ap= 0.64598 time= 1.81337\n",
            "Epoch: 0008 train_loss= 1.32574 val_ap= 0.68316 time= 1.80113\n",
            "Epoch: 0009 train_loss= 1.31411 val_ap= 0.65456 time= 1.83260\n",
            "Epoch: 0010 train_loss= 1.30758 val_ap= 0.65125 time= 1.81193\n",
            "Epoch: 0011 train_loss= 1.30693 val_ap= 0.66320 time= 1.83463\n",
            "Epoch: 0012 train_loss= 1.31330 val_ap= 0.66056 time= 1.80437\n",
            "Epoch: 0013 train_loss= 1.30816 val_ap= 0.65808 time= 1.81212\n",
            "Epoch: 0014 train_loss= 1.31576 val_ap= 0.64278 time= 1.81484\n",
            "Epoch: 0015 train_loss= 1.32035 val_ap= 0.64055 time= 1.82824\n",
            "Epoch: 0016 train_loss= 1.30823 val_ap= 0.65891 time= 1.81928\n",
            "Epoch: 0017 train_loss= 1.31183 val_ap= 0.66584 time= 1.84907\n",
            "Epoch: 0018 train_loss= 1.31096 val_ap= 0.68203 time= 1.82837\n",
            "Epoch: 0019 train_loss= 1.31632 val_ap= 0.64297 time= 1.81513\n",
            "Epoch: 0020 train_loss= 1.31991 val_ap= 0.64089 time= 1.82421\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.735729683004436\n",
            "Test AP score: 0.6447825435133394\n",
            "Settings: 32 64 0.001\n",
            "Epoch: 0001 train_loss= 3.23744 val_ap= 0.65449 time= 1.98908\n",
            "Epoch: 0002 train_loss= 3.25830 val_ap= 0.66652 time= 1.96428\n",
            "Epoch: 0003 train_loss= 3.26538 val_ap= 0.66355 time= 1.98184\n",
            "Epoch: 0004 train_loss= 3.26966 val_ap= 0.65328 time= 1.99368\n",
            "Epoch: 0005 train_loss= 3.24592 val_ap= 0.65118 time= 1.95542\n",
            "Epoch: 0006 train_loss= 3.25899 val_ap= 0.65389 time= 1.91718\n",
            "Epoch: 0007 train_loss= 3.25443 val_ap= 0.64705 time= 1.93678\n",
            "Epoch: 0008 train_loss= 3.25057 val_ap= 0.64809 time= 1.92682\n",
            "Epoch: 0009 train_loss= 3.26585 val_ap= 0.64935 time= 1.94094\n",
            "Epoch: 0010 train_loss= 3.25532 val_ap= 0.65060 time= 1.92900\n",
            "Epoch: 0011 train_loss= 3.24936 val_ap= 0.65483 time= 1.94039\n",
            "Epoch: 0012 train_loss= 3.27562 val_ap= 0.65179 time= 1.93656\n",
            "Epoch: 0013 train_loss= 3.24766 val_ap= 0.66263 time= 1.93838\n",
            "Epoch: 0014 train_loss= 3.25359 val_ap= 0.65174 time= 1.91734\n",
            "Epoch: 0015 train_loss= 3.26156 val_ap= 0.65171 time= 1.91894\n",
            "Epoch: 0016 train_loss= 3.27567 val_ap= 0.64607 time= 1.93450\n",
            "Epoch: 0017 train_loss= 3.25707 val_ap= 0.64508 time= 1.93461\n",
            "Epoch: 0018 train_loss= 3.27524 val_ap= 0.64669 time= 1.94501\n",
            "Epoch: 0019 train_loss= 3.26347 val_ap= 0.66832 time= 1.94002\n",
            "Epoch: 0020 train_loss= 3.25807 val_ap= 0.65326 time= 1.94974\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7464998297081299\n",
            "Test AP score: 0.6619478886804342\n",
            "Settings: 32 64 0.01\n",
            "Epoch: 0001 train_loss= 3.24958 val_ap= 0.65136 time= 1.96494\n",
            "Epoch: 0002 train_loss= 3.25278 val_ap= 0.67043 time= 1.95075\n",
            "Epoch: 0003 train_loss= 3.26487 val_ap= 0.65148 time= 1.96027\n",
            "Epoch: 0004 train_loss= 3.25347 val_ap= 0.64996 time= 1.94443\n",
            "Epoch: 0005 train_loss= 3.26347 val_ap= 0.65151 time= 1.96490\n",
            "Epoch: 0006 train_loss= 3.25149 val_ap= 0.65127 time= 1.95847\n",
            "Epoch: 0007 train_loss= 3.24792 val_ap= 0.65100 time= 1.97509\n",
            "Epoch: 0008 train_loss= 3.26344 val_ap= 0.66785 time= 1.92602\n",
            "Epoch: 0009 train_loss= 3.25648 val_ap= 0.66766 time= 1.95424\n",
            "Epoch: 0010 train_loss= 3.26012 val_ap= 0.67094 time= 1.97727\n",
            "Epoch: 0011 train_loss= 3.23742 val_ap= 0.65421 time= 1.95663\n",
            "Epoch: 0012 train_loss= 3.26938 val_ap= 0.64032 time= 1.93277\n",
            "Epoch: 0013 train_loss= 3.26334 val_ap= 0.65869 time= 1.94469\n",
            "Epoch: 0014 train_loss= 3.24365 val_ap= 0.65238 time= 1.92154\n",
            "Epoch: 0015 train_loss= 3.25553 val_ap= 0.65194 time= 1.92498\n",
            "Epoch: 0016 train_loss= 3.25499 val_ap= 0.64968 time= 1.91805\n",
            "Epoch: 0017 train_loss= 3.24313 val_ap= 0.66170 time= 1.93446\n",
            "Epoch: 0018 train_loss= 3.25882 val_ap= 0.63835 time= 1.93750\n",
            "Epoch: 0019 train_loss= 3.24922 val_ap= 0.65876 time= 1.94229\n",
            "Epoch: 0020 train_loss= 3.24976 val_ap= 0.65115 time= 1.93177\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7446445843458124\n",
            "Test AP score: 0.6581276660191752\n",
            "Settings: 32 64 0.1\n",
            "Epoch: 0001 train_loss= 3.26107 val_ap= 0.65325 time= 1.96541\n",
            "Epoch: 0002 train_loss= 3.26741 val_ap= 0.66043 time= 1.96218\n",
            "Epoch: 0003 train_loss= 3.25410 val_ap= 0.65362 time= 1.98340\n",
            "Epoch: 0004 train_loss= 3.25171 val_ap= 0.66075 time= 1.97511\n",
            "Epoch: 0005 train_loss= 3.24022 val_ap= 0.65261 time= 1.97106\n",
            "Epoch: 0006 train_loss= 3.25504 val_ap= 0.65158 time= 1.96697\n",
            "Epoch: 0007 train_loss= 3.24811 val_ap= 0.66766 time= 1.99447\n",
            "Epoch: 0008 train_loss= 3.23929 val_ap= 0.65267 time= 1.96244\n",
            "Epoch: 0009 train_loss= 3.25788 val_ap= 0.64899 time= 1.95420\n",
            "Epoch: 0010 train_loss= 3.25592 val_ap= 0.65549 time= 1.92749\n",
            "Epoch: 0011 train_loss= 3.24844 val_ap= 0.66122 time= 1.94992\n",
            "Epoch: 0012 train_loss= 3.26511 val_ap= 0.65237 time= 1.93510\n",
            "Epoch: 0013 train_loss= 3.25634 val_ap= 0.64855 time= 1.94930\n",
            "Epoch: 0014 train_loss= 3.26952 val_ap= 0.65041 time= 1.93511\n",
            "Epoch: 0015 train_loss= 3.27293 val_ap= 0.64452 time= 1.94649\n",
            "Epoch: 0016 train_loss= 3.26593 val_ap= 0.65685 time= 1.94220\n",
            "Epoch: 0017 train_loss= 3.25679 val_ap= 0.65198 time= 1.96570\n",
            "Epoch: 0018 train_loss= 3.25107 val_ap= 0.64362 time= 1.98138\n",
            "Epoch: 0019 train_loss= 3.24581 val_ap= 0.65397 time= 1.93780\n",
            "Epoch: 0020 train_loss= 3.25300 val_ap= 0.64387 time= 1.92815\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7399392369038853\n",
            "Test AP score: 0.6517649150023334\n",
            "Settings: 32 32 0.001\n",
            "Epoch: 0001 train_loss= 2.34515 val_ap= 0.66304 time= 1.80245\n",
            "Epoch: 0002 train_loss= 2.35989 val_ap= 0.64690 time= 1.82033\n",
            "Epoch: 0003 train_loss= 2.34174 val_ap= 0.64942 time= 1.81030\n",
            "Epoch: 0004 train_loss= 2.35256 val_ap= 0.65147 time= 1.80974\n",
            "Epoch: 0005 train_loss= 2.35396 val_ap= 0.66240 time= 1.82045\n",
            "Epoch: 0006 train_loss= 2.35933 val_ap= 0.65165 time= 1.78866\n",
            "Epoch: 0007 train_loss= 2.35657 val_ap= 0.66655 time= 1.78921\n",
            "Epoch: 0008 train_loss= 2.34810 val_ap= 0.66685 time= 1.80441\n",
            "Epoch: 0009 train_loss= 2.35465 val_ap= 0.65025 time= 1.81176\n",
            "Epoch: 0010 train_loss= 2.35495 val_ap= 0.65175 time= 1.79617\n",
            "Epoch: 0011 train_loss= 2.35406 val_ap= 0.65713 time= 1.82348\n",
            "Epoch: 0012 train_loss= 2.33561 val_ap= 0.64797 time= 1.80318\n",
            "Epoch: 0013 train_loss= 2.35165 val_ap= 0.66583 time= 1.81956\n",
            "Epoch: 0014 train_loss= 2.34383 val_ap= 0.66546 time= 1.80230\n",
            "Epoch: 0015 train_loss= 2.33620 val_ap= 0.66064 time= 1.79220\n",
            "Epoch: 0016 train_loss= 2.34323 val_ap= 0.66106 time= 1.78554\n",
            "Epoch: 0017 train_loss= 2.34518 val_ap= 0.66957 time= 1.78887\n",
            "Epoch: 0018 train_loss= 2.35304 val_ap= 0.67043 time= 1.80122\n",
            "Epoch: 0019 train_loss= 2.34027 val_ap= 0.66891 time= 1.80701\n",
            "Epoch: 0020 train_loss= 2.35513 val_ap= 0.67381 time= 1.79852\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7663529617329249\n",
            "Test AP score: 0.6886134813237688\n",
            "Settings: 32 32 0.01\n",
            "Epoch: 0001 train_loss= 2.35039 val_ap= 0.65474 time= 1.79592\n",
            "Epoch: 0002 train_loss= 2.34470 val_ap= 0.64964 time= 1.78366\n",
            "Epoch: 0003 train_loss= 2.35541 val_ap= 0.64818 time= 1.84679\n",
            "Epoch: 0004 train_loss= 2.35674 val_ap= 0.64767 time= 1.80326\n",
            "Epoch: 0005 train_loss= 2.33674 val_ap= 0.64151 time= 1.82058\n",
            "Epoch: 0006 train_loss= 2.34033 val_ap= 0.66147 time= 1.83461\n",
            "Epoch: 0007 train_loss= 2.35100 val_ap= 0.64825 time= 1.80488\n",
            "Epoch: 0008 train_loss= 2.35443 val_ap= 0.65373 time= 1.80909\n",
            "Epoch: 0009 train_loss= 2.35162 val_ap= 0.65382 time= 1.79951\n",
            "Epoch: 0010 train_loss= 2.34986 val_ap= 0.66332 time= 1.81191\n",
            "Epoch: 0011 train_loss= 2.33720 val_ap= 0.65049 time= 1.82560\n",
            "Epoch: 0012 train_loss= 2.34567 val_ap= 0.67565 time= 1.79019\n",
            "Epoch: 0013 train_loss= 2.35893 val_ap= 0.65793 time= 1.79823\n",
            "Epoch: 0014 train_loss= 2.35380 val_ap= 0.66338 time= 1.79388\n",
            "Epoch: 0015 train_loss= 2.34401 val_ap= 0.66444 time= 1.81327\n",
            "Epoch: 0016 train_loss= 2.34299 val_ap= 0.66340 time= 1.77986\n",
            "Epoch: 0017 train_loss= 2.33878 val_ap= 0.65053 time= 1.79001\n",
            "Epoch: 0018 train_loss= 2.34559 val_ap= 0.65555 time= 1.77726\n",
            "Epoch: 0019 train_loss= 2.33984 val_ap= 0.66554 time= 1.77410\n",
            "Epoch: 0020 train_loss= 2.35642 val_ap= 0.65398 time= 1.77952\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7471316461752086\n",
            "Test AP score: 0.6622074702923358\n",
            "Settings: 32 32 0.1\n",
            "Epoch: 0001 train_loss= 2.35620 val_ap= 0.66034 time= 1.79591\n",
            "Epoch: 0002 train_loss= 2.35488 val_ap= 0.67258 time= 1.77092\n",
            "Epoch: 0003 train_loss= 2.35705 val_ap= 0.64602 time= 1.79628\n",
            "Epoch: 0004 train_loss= 2.35499 val_ap= 0.63336 time= 1.77852\n",
            "Epoch: 0005 train_loss= 2.35542 val_ap= 0.65278 time= 1.78026\n",
            "Epoch: 0006 train_loss= 2.34060 val_ap= 0.65837 time= 1.75807\n",
            "Epoch: 0007 train_loss= 2.36504 val_ap= 0.65783 time= 1.77578\n",
            "Epoch: 0008 train_loss= 2.34166 val_ap= 0.66196 time= 1.76370\n",
            "Epoch: 0009 train_loss= 2.35834 val_ap= 0.66234 time= 1.79172\n",
            "Epoch: 0010 train_loss= 2.35731 val_ap= 0.66124 time= 1.76720\n",
            "Epoch: 0011 train_loss= 2.35455 val_ap= 0.64543 time= 1.77349\n",
            "Epoch: 0012 train_loss= 2.35140 val_ap= 0.66180 time= 1.77467\n",
            "Epoch: 0013 train_loss= 2.34853 val_ap= 0.64586 time= 1.76983\n",
            "Epoch: 0014 train_loss= 2.34990 val_ap= 0.66993 time= 1.79560\n",
            "Epoch: 0015 train_loss= 2.34291 val_ap= 0.65494 time= 1.78636\n",
            "Epoch: 0016 train_loss= 2.36676 val_ap= 0.64614 time= 1.78066\n",
            "Epoch: 0017 train_loss= 2.36231 val_ap= 0.66626 time= 1.78954\n",
            "Epoch: 0018 train_loss= 2.35094 val_ap= 0.65794 time= 1.78827\n",
            "Epoch: 0019 train_loss= 2.34141 val_ap= 0.65646 time= 1.78355\n",
            "Epoch: 0020 train_loss= 2.36460 val_ap= 0.65900 time= 1.77812\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7480484848448231\n",
            "Test AP score: 0.665167072652038\n",
            "Settings: 32 16 0.001\n",
            "Epoch: 0001 train_loss= 1.73605 val_ap= 0.65818 time= 1.74073\n",
            "Epoch: 0002 train_loss= 1.72202 val_ap= 0.65441 time= 1.72868\n",
            "Epoch: 0003 train_loss= 1.70590 val_ap= 0.66570 time= 1.73330\n",
            "Epoch: 0004 train_loss= 1.73197 val_ap= 0.68110 time= 1.72283\n",
            "Epoch: 0005 train_loss= 1.73535 val_ap= 0.67251 time= 1.73077\n",
            "Epoch: 0006 train_loss= 1.73420 val_ap= 0.64503 time= 1.70187\n",
            "Epoch: 0007 train_loss= 1.74165 val_ap= 0.67362 time= 1.76056\n",
            "Epoch: 0008 train_loss= 1.72795 val_ap= 0.66085 time= 1.74821\n",
            "Epoch: 0009 train_loss= 1.72337 val_ap= 0.65039 time= 1.75982\n",
            "Epoch: 0010 train_loss= 1.71803 val_ap= 0.69098 time= 1.73059\n",
            "Epoch: 0011 train_loss= 1.73203 val_ap= 0.64773 time= 1.75908\n",
            "Epoch: 0012 train_loss= 1.72800 val_ap= 0.65287 time= 1.73449\n",
            "Epoch: 0013 train_loss= 1.71258 val_ap= 0.66881 time= 1.72791\n",
            "Epoch: 0014 train_loss= 1.72878 val_ap= 0.65533 time= 1.72604\n",
            "Epoch: 0015 train_loss= 1.72641 val_ap= 0.65608 time= 1.72584\n",
            "Epoch: 0016 train_loss= 1.72473 val_ap= 0.66720 time= 1.72157\n",
            "Epoch: 0017 train_loss= 1.73143 val_ap= 0.66142 time= 1.72029\n",
            "Epoch: 0018 train_loss= 1.72206 val_ap= 0.66154 time= 1.73737\n",
            "Epoch: 0019 train_loss= 1.70784 val_ap= 0.65270 time= 1.74431\n",
            "Epoch: 0020 train_loss= 1.73899 val_ap= 0.65385 time= 1.71650\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7450455629929721\n",
            "Test AP score: 0.6561947036908172\n",
            "Settings: 32 16 0.01\n",
            "Epoch: 0001 train_loss= 1.72193 val_ap= 0.64702 time= 1.73157\n",
            "Epoch: 0002 train_loss= 1.73544 val_ap= 0.65266 time= 1.72349\n",
            "Epoch: 0003 train_loss= 1.72500 val_ap= 0.65449 time= 1.73230\n",
            "Epoch: 0004 train_loss= 1.71257 val_ap= 0.65352 time= 1.72974\n",
            "Epoch: 0005 train_loss= 1.72489 val_ap= 0.65214 time= 1.72962\n",
            "Epoch: 0006 train_loss= 1.73042 val_ap= 0.65908 time= 1.72343\n",
            "Epoch: 0007 train_loss= 1.73392 val_ap= 0.65241 time= 1.72286\n",
            "Epoch: 0008 train_loss= 1.74360 val_ap= 0.64906 time= 1.72328\n",
            "Epoch: 0009 train_loss= 1.72509 val_ap= 0.67685 time= 1.73802\n",
            "Epoch: 0010 train_loss= 1.73759 val_ap= 0.65161 time= 1.71918\n",
            "Epoch: 0011 train_loss= 1.72700 val_ap= 0.66795 time= 1.74318\n",
            "Epoch: 0012 train_loss= 1.72268 val_ap= 0.66029 time= 1.72012\n",
            "Epoch: 0013 train_loss= 1.71100 val_ap= 0.66232 time= 1.73603\n",
            "Epoch: 0014 train_loss= 1.72579 val_ap= 0.64749 time= 1.72845\n",
            "Epoch: 0015 train_loss= 1.73161 val_ap= 0.66181 time= 1.72506\n",
            "Epoch: 0016 train_loss= 1.73142 val_ap= 0.66825 time= 1.72722\n",
            "Epoch: 0017 train_loss= 1.73490 val_ap= 0.64946 time= 1.76932\n",
            "Epoch: 0018 train_loss= 1.72302 val_ap= 0.66072 time= 1.76009\n",
            "Epoch: 0019 train_loss= 1.73680 val_ap= 0.67189 time= 1.73421\n",
            "Epoch: 0020 train_loss= 1.72769 val_ap= 0.67748 time= 1.73177\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7662363211532747\n",
            "Test AP score: 0.6857004909959316\n",
            "Settings: 32 16 0.1\n",
            "Epoch: 0001 train_loss= 1.73919 val_ap= 0.65311 time= 1.74587\n",
            "Epoch: 0002 train_loss= 1.72253 val_ap= 0.65882 time= 1.76168\n",
            "Epoch: 0003 train_loss= 1.72918 val_ap= 0.65977 time= 1.74282\n",
            "Epoch: 0004 train_loss= 1.72654 val_ap= 0.64912 time= 1.74716\n",
            "Epoch: 0005 train_loss= 1.72739 val_ap= 0.63933 time= 1.73571\n",
            "Epoch: 0006 train_loss= 1.72394 val_ap= 0.65134 time= 1.73017\n",
            "Epoch: 0007 train_loss= 1.73481 val_ap= 0.66861 time= 1.72425\n",
            "Epoch: 0008 train_loss= 1.72500 val_ap= 0.65392 time= 1.73213\n",
            "Epoch: 0009 train_loss= 1.73624 val_ap= 0.64068 time= 1.75551\n",
            "Epoch: 0010 train_loss= 1.72209 val_ap= 0.65500 time= 1.72921\n",
            "Epoch: 0011 train_loss= 1.72619 val_ap= 0.65617 time= 1.74830\n",
            "Epoch: 0012 train_loss= 1.73643 val_ap= 0.65745 time= 1.75171\n",
            "Epoch: 0013 train_loss= 1.73359 val_ap= 0.66267 time= 1.78048\n",
            "Epoch: 0014 train_loss= 1.72395 val_ap= 0.64927 time= 1.76442\n",
            "Epoch: 0015 train_loss= 1.72781 val_ap= 0.66286 time= 1.76866\n",
            "Epoch: 0016 train_loss= 1.73607 val_ap= 0.65472 time= 1.75562\n",
            "Epoch: 0017 train_loss= 1.72602 val_ap= 0.64784 time= 1.76149\n",
            "Epoch: 0018 train_loss= 1.73658 val_ap= 0.65802 time= 1.74317\n",
            "Epoch: 0019 train_loss= 1.72666 val_ap= 0.64593 time= 1.73698\n",
            "Epoch: 0020 train_loss= 1.71382 val_ap= 0.65018 time= 1.76030\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7428497561027532\n",
            "Test AP score: 0.6572179776833906\n",
            "Settings: 32 8 0.001\n",
            "Epoch: 0001 train_loss= 1.31275 val_ap= 0.65154 time= 1.75204\n",
            "Epoch: 0002 train_loss= 1.31983 val_ap= 0.65729 time= 1.74826\n",
            "Epoch: 0003 train_loss= 1.29969 val_ap= 0.62736 time= 1.74641\n",
            "Epoch: 0004 train_loss= 1.30753 val_ap= 0.65088 time= 1.74238\n",
            "Epoch: 0005 train_loss= 1.31380 val_ap= 0.65838 time= 1.75562\n",
            "Epoch: 0006 train_loss= 1.31311 val_ap= 0.67800 time= 1.75574\n",
            "Epoch: 0007 train_loss= 1.31729 val_ap= 0.65797 time= 1.74821\n",
            "Epoch: 0008 train_loss= 1.32272 val_ap= 0.67061 time= 1.73497\n",
            "Epoch: 0009 train_loss= 1.30400 val_ap= 0.66104 time= 1.73871\n",
            "Epoch: 0010 train_loss= 1.31254 val_ap= 0.65400 time= 1.72165\n",
            "Epoch: 0011 train_loss= 1.31466 val_ap= 0.66455 time= 1.77077\n",
            "Epoch: 0012 train_loss= 1.30925 val_ap= 0.66034 time= 1.72372\n",
            "Epoch: 0013 train_loss= 1.32009 val_ap= 0.66936 time= 1.75061\n",
            "Epoch: 0014 train_loss= 1.31440 val_ap= 0.65398 time= 1.75966\n",
            "Epoch: 0015 train_loss= 1.30274 val_ap= 0.65410 time= 1.75204\n",
            "Epoch: 0016 train_loss= 1.30921 val_ap= 0.67355 time= 1.72658\n",
            "Epoch: 0017 train_loss= 1.30360 val_ap= 0.67836 time= 1.76696\n",
            "Epoch: 0018 train_loss= 1.31697 val_ap= 0.67172 time= 1.73360\n",
            "Epoch: 0019 train_loss= 1.31094 val_ap= 0.66033 time= 1.72379\n",
            "Epoch: 0020 train_loss= 1.31905 val_ap= 0.64578 time= 1.70788\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7392503440288487\n",
            "Test AP score: 0.6506061207463021\n",
            "Settings: 32 8 0.01\n",
            "Epoch: 0001 train_loss= 1.30401 val_ap= 0.66056 time= 1.73456\n",
            "Epoch: 0002 train_loss= 1.31571 val_ap= 0.68155 time= 1.71236\n",
            "Epoch: 0003 train_loss= 1.31026 val_ap= 0.64613 time= 1.72979\n",
            "Epoch: 0004 train_loss= 1.31258 val_ap= 0.64341 time= 1.71798\n",
            "Epoch: 0005 train_loss= 1.32403 val_ap= 0.67407 time= 1.70785\n",
            "Epoch: 0006 train_loss= 1.31054 val_ap= 0.65518 time= 1.72140\n",
            "Epoch: 0007 train_loss= 1.30972 val_ap= 0.65757 time= 1.73736\n",
            "Epoch: 0008 train_loss= 1.31429 val_ap= 0.64814 time= 1.71228\n",
            "Epoch: 0009 train_loss= 1.31146 val_ap= 0.64914 time= 1.72720\n",
            "Epoch: 0010 train_loss= 1.28915 val_ap= 0.66879 time= 1.71032\n",
            "Epoch: 0011 train_loss= 1.31479 val_ap= 0.65519 time= 1.70964\n",
            "Epoch: 0012 train_loss= 1.32791 val_ap= 0.63237 time= 1.71824\n",
            "Epoch: 0013 train_loss= 1.32121 val_ap= 0.66370 time= 1.73783\n",
            "Epoch: 0014 train_loss= 1.31179 val_ap= 0.64600 time= 1.80217\n",
            "Epoch: 0015 train_loss= 1.31794 val_ap= 0.64668 time= 1.75554\n",
            "Epoch: 0016 train_loss= 1.31735 val_ap= 0.66808 time= 1.74964\n",
            "Epoch: 0017 train_loss= 1.30625 val_ap= 0.64267 time= 1.73939\n",
            "Epoch: 0018 train_loss= 1.31987 val_ap= 0.68530 time= 1.74496\n",
            "Epoch: 0019 train_loss= 1.32505 val_ap= 0.66909 time= 1.75364\n",
            "Epoch: 0020 train_loss= 1.31811 val_ap= 0.66913 time= 1.77272\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7613006023471286\n",
            "Test AP score: 0.6781443857340639\n",
            "Settings: 32 8 0.1\n",
            "Epoch: 0001 train_loss= 1.31134 val_ap= 0.68593 time= 1.74001\n",
            "Epoch: 0002 train_loss= 1.31666 val_ap= 0.65674 time= 1.72498\n",
            "Epoch: 0003 train_loss= 1.31024 val_ap= 0.66451 time= 1.73834\n",
            "Epoch: 0004 train_loss= 1.31136 val_ap= 0.63985 time= 1.75311\n",
            "Epoch: 0005 train_loss= 1.31041 val_ap= 0.66324 time= 1.74162\n",
            "Epoch: 0006 train_loss= 1.32878 val_ap= 0.65374 time= 1.72066\n",
            "Epoch: 0007 train_loss= 1.31419 val_ap= 0.66010 time= 1.70882\n",
            "Epoch: 0008 train_loss= 1.31704 val_ap= 0.64484 time= 1.69964\n",
            "Epoch: 0009 train_loss= 1.32029 val_ap= 0.64024 time= 1.71297\n",
            "Epoch: 0010 train_loss= 1.31358 val_ap= 0.68801 time= 1.69470\n",
            "Epoch: 0011 train_loss= 1.30888 val_ap= 0.66843 time= 1.73173\n",
            "Epoch: 0012 train_loss= 1.31568 val_ap= 0.66966 time= 1.72064\n",
            "Epoch: 0013 train_loss= 1.30697 val_ap= 0.65939 time= 1.71246\n",
            "Epoch: 0014 train_loss= 1.31222 val_ap= 0.66253 time= 1.70642\n",
            "Epoch: 0015 train_loss= 1.32428 val_ap= 0.66708 time= 1.71948\n",
            "Epoch: 0016 train_loss= 1.30920 val_ap= 0.65703 time= 1.70655\n",
            "Epoch: 0017 train_loss= 1.30543 val_ap= 0.64445 time= 1.72351\n",
            "Epoch: 0018 train_loss= 1.31253 val_ap= 0.67480 time= 1.71384\n",
            "Epoch: 0019 train_loss= 1.31188 val_ap= 0.66869 time= 1.70328\n",
            "Epoch: 0020 train_loss= 1.29934 val_ap= 0.65045 time= 1.72049\n",
            "Optimization Finished!\n",
            "Test ROC score: 0.7513080017561125\n",
            "Test AP score: 0.6585134326359975\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}